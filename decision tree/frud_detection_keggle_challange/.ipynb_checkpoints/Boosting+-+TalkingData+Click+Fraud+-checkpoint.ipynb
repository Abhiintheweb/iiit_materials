{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# TalkingData: Fraudulent Click Prediction\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will apply various boosting algorithms to solve an interesting classification problem from the domain of 'digital fraud'.\n",
    "\n",
    "The analysis is divided into the following sections:\n",
    "- Understanding the business problem\n",
    "- Understanding and exploring the data\n",
    "- Feature engineering: Creating new features\n",
    "- Model building and evaluation: AdaBoost\n",
    "- Modelling building and evaluation: Gradient Boosting\n",
    "- Modelling building and evaluation: XGBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Business Problem\n",
    "\n",
    "<a href=\"https://www.talkingdata.com/\">TalkingData</a> is a Chinese big data company, and one of their areas of expertise is mobile advertisements.\n",
    "\n",
    "In mobile advertisements, **click fraud** is a major source of losses. Click fraud is the practice of repeatedly clicking on an advertisement hosted on a website with the intention of generating revenue for the host website or draining revenue from the advertiser.\n",
    "\n",
    "In this case, TalkingData happens to be serving the advertisers (their clients). TalkingData cover a whopping **approx. 70% of the active mobile devices in China**, of which 90% are potentially fraudulent (i.e. the user is actually not going to download the app after clicking).\n",
    "\n",
    "You can imagine the amount of money they can help clients save if they are able to predict whether a given click is fraudulent (or equivalently, whether a given click will result in a download). \n",
    "\n",
    "Their current approach to solve this problem is that they've generated a blacklist of IP addresses - those IPs which produce lots of clicks, but never install any apps. Now, they want to try some advanced techniques to predict the probability of a click being genuine/fraud.\n",
    "\n",
    "In this problem, we will use the features associated with clicks, such as IP address, operating system, device type, time of click etc. to predict the probability of a click being fraud.\n",
    "\n",
    "They have released <a href=\"https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection\">the problem on Kaggle here.</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding and Exploring the Data\n",
    "\n",
    "The data contains observations of about 240 million clicks, and whether a given click resulted in a download or not (1/0). \n",
    "\n",
    "On Kaggle, the data is split into train.csv and train_sample.csv (100,000 observations). We'll use the smaller train_sample.csv in this notebook for speed, though while training the model for Kaggle submissions, the full training data will obviously produce better results.\n",
    "\n",
    "The detailed data dictionary is mentioned here:\n",
    "- ```ip```: ip address of click.\n",
    "- ```app```: app id for marketing.\n",
    "- ```device```: device type id of user mobile phone (e.g., iphone 6 plus, iphone 7, huawei mate 7, etc.)\n",
    "- ```os```: os version id of user mobile phone\n",
    "- ```channel```: channel id of mobile ad publisher\n",
    "- ```click_time```: timestamp of click (UTC)\n",
    "- ```attributed_time```: if user download the app for after clicking an ad, this is the time of the app download\n",
    "- ```is_attributed```: the target that is to be predicted, indicating the app was downloaded\n",
    "\n",
    "Let's try finding some useful trends in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "5ba86a36-b8be-44db-ad92-e3cddbb354d1",
    "_uuid": "cd4d66f4ecc6daa0ea4cab6359fc5203112f245c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhi/venvs/notebook/local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named xgboost",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c244b79090b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named xgboost"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "import gc # for deleting unused variables\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d408baf0-f640-45f3-8dec-141746a985a8",
    "_uuid": "7a3dc1d7ebed1cdc9818338682bf5858e276681e"
   },
   "source": [
    "#### Reading the Data  \n",
    "\n",
    "The code below reads the train_sample.csv file if you set testing = True, else reads the full train.csv file. You can read the sample while tuning the model etc., and then run the model on the full data once done.\n",
    "\n",
    "#### Important Note: Save memory when the data is huge\n",
    "\n",
    "Since the training data is quite huge, the program will be quite slow if you don't consciously follow some best practices to save memory. This notebook demonstrates some of those practices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "54ed4833-efb3-4adf-971b-28a56ae19d01",
    "_uuid": "bac7dea7334ff1fb925347f9302b3d06e189fbc7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# reading training data\n",
    "\n",
    "# specify column dtypes to save memory (by default pandas reads some columns as floats)\n",
    "dtypes = {\n",
    "        'ip'            : 'uint16',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32' # note that click_id is only in test data, not training data\n",
    "        }\n",
    "\n",
    "# read training_sample.csv for quick testing/debug, else read the full train.csv\n",
    "testing = True\n",
    "if testing:\n",
    "    train_path = \"train_sample.csv\"\n",
    "    skiprows = None\n",
    "    nrows = None\n",
    "    colnames=['ip','app','device','os', 'channel', 'click_time', 'is_attributed']\n",
    "else:\n",
    "    train_path = \"train.csv\"\n",
    "    skiprows = range(1, 144903891)\n",
    "    nrows = 10000000\n",
    "    colnames=['ip','app','device','os', 'channel', 'click_time', 'is_attributed']\n",
    "\n",
    "# read training data\n",
    "train_sample = pd.read_csv(train_path, skiprows=skiprows, nrows=nrows, dtype=dtypes, usecols=colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "98d1b00a-8ee6-4959-9091-e8b56e4bcb15",
    "_uuid": "a9f5559317e6cc476c47b166bd95118c9f29dbbe"
   },
   "outputs": [],
   "source": [
    "# length of training data\n",
    "len(train_sample.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7743ffd9-a38c-4130-b7d4-373e324bd9ae",
    "_uuid": "663ed1e0137fce0f2a5b2ebd02c7bf6a35c506c7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Displays memory consumed by each column ---\n",
    "print(train_sample.memory_usage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "196408ab-7891-4f75-bf3a-c491525ab4ff",
    "_uuid": "4c4323fe3fdf0f12fd065c83b253385a5826413c"
   },
   "outputs": [],
   "source": [
    "# space used by training data\n",
    "print('Training dataset uses {0} MB'.format(train_sample.memory_usage().sum()/1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "85dce024-c56b-412d-b230-7a42d1e61661",
    "_uuid": "831d573b61c925fed93c55d4a4094e2f374e727b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training data top rows\n",
    "train_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "047cdedb-b9a4-4185-9079-31d19e418dd5",
    "_uuid": "bdca59dbbab3ea6e7938ed6348bda8b022b54437"
   },
   "source": [
    "### Exploring the Data - Univariate Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f1924177-9395-4f17-bbec-6746cf8c360e",
    "_uuid": "778a6efbfc8c7c9d82f6aa6c84af3e145777be13"
   },
   "source": [
    "Let's now understand and explore the data. Let's start with understanding the size and data types of the train_sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4539d9f9-fe8e-438b-9c6e-8d0f4d089e17",
    "_uuid": "0aff4ad2d4abb7a49cfeccbd0d65f96a5256eab8"
   },
   "outputs": [],
   "source": [
    "# look at non-null values, number of entries etc.\n",
    "# there are no missing values\n",
    "train_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dd930aa6-557f-4b59-9a36-8f940324f594",
    "_uuid": "816535e82869da6601f9dd7227a201adda9843d1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Basic exploratory analysis \n",
    "\n",
    "# Number of unique values in each column\n",
    "def fraction_unique(x):\n",
    "    return len(train_sample[x].unique())\n",
    "\n",
    "number_unique_vals = {x: fraction_unique(x) for x in train_sample.columns}\n",
    "number_unique_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "408e795a-2d0d-4ae0-bf96-868721d9394d",
    "_uuid": "c6bd82f7f439f73bf543d2313c82e4d3e99519e4"
   },
   "outputs": [],
   "source": [
    "# All columns apart from click time are originally int type, \n",
    "# though note that they are all actually categorical \n",
    "train_sample.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a329709b-2d48-4b32-8491-d0a3a57a9635",
    "_uuid": "16271bff54cffd07c656c21023b0a1cb62297960"
   },
   "source": [
    "There are certain 'apps' which have quite high number of instances/rows (each row is a click). The plot below shows this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3e9c25d8-31a7-4b43-b2ac-5ecc21921f26",
    "_uuid": "b99fbb4955c7f05d78495d958d16d673479aca64",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # distribution of 'app' \n",
    "# # some 'apps' have a disproportionately high number of clicks (>15k), and some are very rare (3-4)\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.countplot(x=\"app\", data=train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "77e73dce-cf2f-43a9-b0a8-fe5956ff99a9",
    "_uuid": "d3815fab7e31db39452c9fca0b3ade757124da25"
   },
   "outputs": [],
   "source": [
    "# # distribution of 'device' \n",
    "# # this is expected because a few popular devices are used heavily\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.countplot(x=\"device\", data=train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "098c5d37-5302-45e8-9845-eb3dfa7be87b",
    "_uuid": "656c6cfa30d189febea9bb4c12b2f2519c0b0cef"
   },
   "outputs": [],
   "source": [
    "# # channel: various channels get clicks in comparable quantities\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.countplot(x=\"channel\", data=train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c39356d4-3f97-41be-944f-ce88db264365",
    "_uuid": "8f33610186e195da39033b9a64cd2d11b244113a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # os: there are a couple commos OSes (android and ios?), though some are rare and can indicate suspicion \n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.countplot(x=\"os\", data=train_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a52d4651-f5ca-45e0-8b20-ec1f70d80edb",
    "_uuid": "6604d330cee83328b4e28790829c82b40fe83ef1"
   },
   "source": [
    "Let's now look at the distribution of the target  variable 'is_attributed'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "332d0c92-31f6-4109-91ba-5d1f38725ca8",
    "_uuid": "755b0ff3de0028805b6e33fe5b6fb70e5a1247d5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # target variable distribution\n",
    "100*(train_sample['is_attributed'].astype('object').value_counts()/len(train_sample.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "030933bd-d06b-42c8-8d1e-882f70776a74",
    "_uuid": "b604a87e4ca95bbcbe40e3192f7b66774c03d84d"
   },
   "source": [
    "Only **about 0.2% of clicks are 'fraudulent'**, which is expected in a fraud detection problem. Such high class imbalance is probably going to be the toughest challenge of this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7285fbce-6dd1-4638-80c6-8f8d94d1593c",
    "_uuid": "bca20461412ff0d2ba2d87a515785e8a762fd343"
   },
   "source": [
    "### Exploring the Data - Segmented Univariate Analysis\n",
    "\n",
    "Let's now look at how the target variable varies with the various predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "73089123-995e-4142-8aa9-784bbcddccb2",
    "_uuid": "1a5d777dc7d2a003752eefd8af94c4433099bf44",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the average of 'is_attributed', or 'download rate'\n",
    "# with app (clearly this is non-readable)\n",
    "app_target = train_sample.groupby('app').is_attributed.agg(['mean', 'count'])\n",
    "app_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly non-readable, so let's first get rid of all the apps that are very rare (say which comprise of less than 20% clicks) and plot the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frequent_apps = train_sample.groupby('app').size().reset_index(name='count')\n",
    "frequent_apps = frequent_apps[frequent_apps['count']>frequent_apps['count'].quantile(0.80)]\n",
    "frequent_apps = frequent_apps.merge(train_sample, on='app', how='inner')\n",
    "frequent_apps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.countplot(y=\"app\", hue=\"is_attributed\", data=frequent_apps);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do lots of other interesting ananlysis with the existing features. For now, let's create some new features which will probably improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "40f6f8d9-bd39-4876-bca8-5dcaa14eed04",
    "_uuid": "b76d4314871b8db705dc26b51f4ba07df2cd857b"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now derive some new features from the existing ones. There are a number of features one can extract from ```click_time``` itself, and by grouping combinations of IP with other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9963886f-8f33-4ff4-be76-0a28e8d6ba8b",
    "_uuid": "833037301451ca4d6939909f8cfd47314834b7b9"
   },
   "source": [
    "### Datetime Based Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fd611758-c8ec-4401-9875-1eb760ccddb7",
    "_uuid": "a38688f6b07581964699b4a8c41100844f21090c"
   },
   "outputs": [],
   "source": [
    "# Creating datetime variables\n",
    "# takes in a df, adds date/time based columns to it, and returns the modified df\n",
    "def timeFeatures(df):\n",
    "    # Derive new features using the click_time column\n",
    "    df['datetime'] = pd.to_datetime(df['click_time'])\n",
    "    df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "    df[\"day_of_year\"] = df[\"datetime\"].dt.dayofyear\n",
    "    df[\"month\"] = df[\"datetime\"].dt.month\n",
    "    df[\"hour\"] = df[\"datetime\"].dt.hour\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "237df241-844b-4003-b906-298432b8d868",
    "_uuid": "694177530d20a1e33801d6053a88d99f28cfd88c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating new datetime variables and dropping the old ones\n",
    "train_sample = timeFeatures(train_sample)\n",
    "train_sample.drop(['click_time', 'datetime'], axis=1, inplace=True)\n",
    "train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4cfe36bc-b218-48ce-ac97-9b9da3758d2f",
    "_uuid": "0eead49461cc6e85bf733b2682c95b098c6b4762"
   },
   "outputs": [],
   "source": [
    "# datatypes\n",
    "# note that by default the new datetime variables are int64\n",
    "train_sample.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2c94cc5a-7f24-4321-8b64-75835eb769a1",
    "_uuid": "72fab86bd46e38c8707d48a88d4cfd9122768e5b"
   },
   "outputs": [],
   "source": [
    "# memory used by training data\n",
    "print('Training dataset uses {0} MB'.format(train_sample.memory_usage().sum()/1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "630048e3-b363-4eb7-8620-fc7c0aed8794",
    "_uuid": "f358d55b47fdd1f3458fc640a37b83f93abd01d9"
   },
   "outputs": [],
   "source": [
    "# lets convert the variables back to lower dtype again\n",
    "int_vars = ['app', 'device', 'os', 'channel', 'day_of_week','day_of_year', 'month', 'hour']\n",
    "train_sample[int_vars] = train_sample[int_vars].astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bfb0e108-be87-4f1f-8690-b6a0dd253d5f",
    "_uuid": "2ad5b5082c465d89a3749ef500121a0068fc7abe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_sample.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "097f83a0-d7a0-486e-8315-33e4d351349e",
    "_uuid": "7d31b2a2d63b9a7637489768da96c6833079e19e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# space used by training data\n",
    "print('Training dataset uses {0} MB'.format(train_sample.memory_usage().sum()/1024**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f1a41e27-1c82-42a1-b06f-2b2d384cecee",
    "_uuid": "1a82f07ac45c9a68893d104349971344ef7aa32b"
   },
   "source": [
    "### IP Grouping Based Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1cbfe97f-6915-4e84-b63b-35c3b3933f68",
    "_uuid": "0af86c9bec412b948482bcec80c7df233f1b7c39"
   },
   "source": [
    "Let's now create some important features by grouping IP addresses with features such as os, channel, hour, day etc. Also, count of each IP address will also be a feature.\n",
    "\n",
    "Note that though we are deriving new features by grouping IP addresses, using IP adress itself as a features is not a good idea. This is because (in the test data) if a new IP address is seen, the model will see a new 'category' and will not be able to make predictions (IP is a categorical variable, it has just been encoded with numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b0cd1ca3-e3ef-414b-b9cc-add42aebf813",
    "_uuid": "59690cdbb2b67074d81b9be15375e6ffb0b8f85e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# number of clicks by count of IP address\n",
    "# note that we are explicitly asking pandas to re-encode the aggregated features \n",
    "# as 'int16' to save memory\n",
    "ip_count = train_sample.groupby('ip').size().reset_index(name='ip_count').astype('int16')\n",
    "ip_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now merge this dataframe with the original training df. Similarly, we can create combinations of various features such as ip_day_hour (count of ip-day-hour combinations), ip_hour_channel, ip_hour_app, etc. \n",
    "\n",
    "The following function takes in a dataframe and creates these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates groupings of IP addresses with other features and appends the new features to the df\n",
    "def grouped_features(df):\n",
    "    # ip_count\n",
    "    ip_count = df.groupby('ip').size().reset_index(name='ip_count').astype('uint16')\n",
    "    ip_day_hour = df.groupby(['ip', 'day_of_week', 'hour']).size().reset_index(name='ip_day_hour').astype('uint16')\n",
    "    ip_hour_channel = df[['ip', 'hour', 'channel']].groupby(['ip', 'hour', 'channel']).size().reset_index(name='ip_hour_channel').astype('uint16')\n",
    "    ip_hour_os = df.groupby(['ip', 'hour', 'os']).channel.count().reset_index(name='ip_hour_os').astype('uint16')\n",
    "    ip_hour_app = df.groupby(['ip', 'hour', 'app']).channel.count().reset_index(name='ip_hour_app').astype('uint16')\n",
    "    ip_hour_device = df.groupby(['ip', 'hour', 'device']).channel.count().reset_index(name='ip_hour_device').astype('uint16')\n",
    "    \n",
    "    # merge the new aggregated features with the df\n",
    "    df = pd.merge(df, ip_count, on='ip', how='left')\n",
    "    del ip_count\n",
    "    df = pd.merge(df, ip_day_hour, on=['ip', 'day_of_week', 'hour'], how='left')\n",
    "    del ip_day_hour\n",
    "    df = pd.merge(df, ip_hour_channel, on=['ip', 'hour', 'channel'], how='left')\n",
    "    del ip_hour_channel\n",
    "    df = pd.merge(df, ip_hour_os, on=['ip', 'hour', 'os'], how='left')\n",
    "    del ip_hour_os\n",
    "    df = pd.merge(df, ip_hour_app, on=['ip', 'hour', 'app'], how='left')\n",
    "    del ip_hour_app\n",
    "    df = pd.merge(df, ip_hour_device, on=['ip', 'hour', 'device'], how='left')\n",
    "    del ip_hour_device\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = grouped_features(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dcb86f85-6418-40dd-8e4a-670f1df0b3fc",
    "_uuid": "3fffc4f935664d861cc0556f78f654c0c7121dac",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e01b730e-a9a3-4899-a867-3d3da43d1670",
    "_uuid": "e819b6938609e7a2c96e3bea97d83afeea10457d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Training dataset uses {0} MB'.format(train_sample.memory_usage().sum()/1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e1c25766-1a45-416e-bcd0-865aa8c83e0f",
    "_uuid": "70d49f6f951fc870e404dc11f5643b39a5fe2a36",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# garbage collect (unused) object\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "Let's now build models to predict the variable ```is_attributed``` (downloaded). We'll try the several variants of boosting (adaboost, gradient boosting and XGBoost), tune the hyperparameters in each model and choose the one which gives the best performance.\n",
    "\n",
    "In the original Kaggle competition, the metric for model evaluation is **area under the ROC curve**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2b85ad1e-932b-4570-99ad-df89d8e09eee",
    "_uuid": "fb851915b9cd57bb5fd85a0d08b317c695db015b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create x and y train\n",
    "X = train_sample.drop('is_attributed', axis=1)\n",
    "y = train_sample[['is_attributed']]\n",
    "\n",
    "# split data into train and test/validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d0e93c90-38df-486b-b7e5-52c82b21d821",
    "_uuid": "116f681214fa50bf5710df325d37203a10d66df2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check the average download rates in train and test data, should be comparable\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaboost classifier with max 600 decision trees of depth=2\n",
    "# learning_rate/shrinkage=1.5\n",
    "\n",
    "# base estimator\n",
    "tree = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "# adaboost with the tree as base estimator\n",
    "adaboost_model_1 = AdaBoostClassifier(\n",
    "    base_estimator=tree,\n",
    "    n_estimators=600,\n",
    "    learning_rate=1.5,\n",
    "    algorithm=\"SAMME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "adaboost_model_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predictions\n",
    "# the second column represents the probability of a click resulting in a download\n",
    "predictions = adaboost_model_1.predict_proba(X_test)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics: AUC\n",
    "metrics.roc_auc_score(y_test, predictions[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost - Hyperparameter Tuning\n",
    "\n",
    "Let's now tune the hyperparameters of the AdaBoost classifier. In this case, we have two types of hyperparameters - those of the component trees (max_depth etc.) and those of the ensemble (n_estimators, learning_rate etc.). \n",
    "\n",
    "\n",
    "We can tune both using the following technique - the keys of the form ```base_estimator_parameter_name``` belong to the trees (base estimator), and the rest belong to the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter grid\n",
    "param_grid = {\"base_estimator__max_depth\" : [2, 5],\n",
    "              \"n_estimators\": [200, 400, 600]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base estimator\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# adaboost with the tree as base estimator\n",
    "# learning rate is arbitrarily set to 0.6, we'll discuss learning_rate below\n",
    "ABC = AdaBoostClassifier(\n",
    "    base_estimator=tree,\n",
    "    learning_rate=0.6,\n",
    "    algorithm=\"SAMME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run grid search\n",
    "folds = 3\n",
    "grid_search_ABC = GridSearchCV(ABC, \n",
    "                               cv = folds,\n",
    "                               param_grid=param_grid, \n",
    "                               scoring = 'roc_auc', \n",
    "                               return_train_score=True,                         \n",
    "                               verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit \n",
    "grid_search_ABC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(grid_search_ABC.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting AUC with hyperparameter combinations\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "for n, depth in enumerate(param_grid['base_estimator__max_depth']):\n",
    "    \n",
    "\n",
    "    # subplot 1/n\n",
    "    plt.subplot(1,3, n+1)\n",
    "    depth_df = cv_results[cv_results['param_base_estimator__max_depth']==depth]\n",
    "\n",
    "    plt.plot(depth_df[\"param_n_estimators\"], depth_df[\"mean_test_score\"])\n",
    "    plt.plot(depth_df[\"param_n_estimators\"], depth_df[\"mean_train_score\"])\n",
    "    plt.xlabel('n_estimators')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.title(\"max_depth={0}\".format(depth))\n",
    "    plt.ylim([0.60, 1])\n",
    "    plt.legend(['test score', 'train score'], loc='upper left')\n",
    "    plt.xscale('log')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above show that:\n",
    "- The ensemble with max_depth=5 is clearly overfitting (training auc is almost 1, while the test score is much lower)\n",
    "- At max_depth=2, the model performs slightly better (approx 95% AUC) with a higher test score \n",
    "\n",
    "Thus, we should go ahead with ```max_depth=2``` and ```n_estimators=200```.\n",
    "\n",
    "Note that we haven't experimented with many other important hyperparameters till now, such as ```learning rate```, ```subsample``` etc., and the results might be considerably improved by tuning them. We'll next experiment with these hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model performance on test data with chosen hyperparameters\n",
    "\n",
    "# base estimator\n",
    "tree = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "# adaboost with the tree as base estimator\n",
    "# learning rate is arbitrarily set, we'll discuss learning_rate below\n",
    "ABC = AdaBoostClassifier(\n",
    "    base_estimator=tree,\n",
    "    learning_rate=0.6,\n",
    "    n_estimators=200,\n",
    "    algorithm=\"SAMME\")\n",
    "\n",
    "ABC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "predictions = ABC.predict_proba(X_test)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc auc\n",
    "metrics.roc_auc_score(y_test, predictions[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier\n",
    "\n",
    "Let's now try the gradient boosting classifier. We'll experiment with two main hyperparameters now - ```learning_rate``` (shrinkage) and ```subsample```. \n",
    "\n",
    "By adjusting the learning rate to less than 1, we can regularize the model. A model with higher learning_rate learns fast, but is prone to overfitting; one with a lower learning rate learns slowly, but avoids overfitting.\n",
    "\n",
    "Also, there's a trade-off between ```learning_rate``` and ```n_estimators``` - the higher the learning rate, the lesser trees the model needs (and thus we usually tune only one of them).\n",
    "\n",
    "Also, by subsampling (setting ```subsample``` to less than 1), we can have the individual models built on random subsamples of size ```subsample```. That way, each tree will be trained on different subsets and reduce the model's variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter grid\n",
    "param_grid = {\"learning_rate\": [0.2, 0.6, 0.9],\n",
    "              \"subsample\": [0.3, 0.6, 0.9]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaboost with the tree as base estimator\n",
    "GBC = GradientBoostingClassifier(max_depth=2, n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run grid search\n",
    "folds = 3\n",
    "grid_search_GBC = GridSearchCV(GBC, \n",
    "                               cv = folds,\n",
    "                               param_grid=param_grid, \n",
    "                               scoring = 'roc_auc', \n",
    "                               return_train_score=True,                         \n",
    "                               verbose = 1)\n",
    "\n",
    "grid_search_GBC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(grid_search_GBC.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "\n",
    "for n, subsample in enumerate(param_grid['subsample']):\n",
    "    \n",
    "\n",
    "    # subplot 1/n\n",
    "    plt.subplot(1,len(param_grid['subsample']), n+1)\n",
    "    df = cv_results[cv_results['param_subsample']==subsample]\n",
    "\n",
    "    plt.plot(df[\"param_learning_rate\"], df[\"mean_test_score\"])\n",
    "    plt.plot(df[\"param_learning_rate\"], df[\"mean_train_score\"])\n",
    "    plt.xlabel('learning_rate')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.title(\"subsample={0}\".format(subsample))\n",
    "    plt.ylim([0.60, 1])\n",
    "    plt.legend(['test score', 'train score'], loc='upper left')\n",
    "    plt.xscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear from the plot above that the model with a lower subsample ratio performs better, while those with higher subsamples tend to overfit. \n",
    "\n",
    "Also, a lower learning rate results in less overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "Let's finally try XGBoost. The hyperparameters are the same, some important ones being ```subsample```, ```learning_rate```, ```max_depth``` etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2c974205-ceae-45d7-ac5c-06c49449e772",
    "_uuid": "25d4621636d95e27ee661f4d6a62532671f678b6"
   },
   "outputs": [],
   "source": [
    "# fit model on training data with default hyperparameters\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3d7ecd8f-856e-4405-9251-4128a31501b4",
    "_uuid": "92d6a9195af92f42514cbeec09585b083bc304cf"
   },
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "# use predict_proba since we need probabilities to compute auc\n",
    "y_pred = model.predict_proba(X_test)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "26c5a5e3-b0ab-4b38-b31e-02aa2f94b6d2",
    "_uuid": "6761becf4d2447a77b9df32f7bb36b9331a16234",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "roc = metrics.roc_auc_score(y_test, y_pred[:, 1])\n",
    "print(\"AUC: %.2f%%\" % (roc * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1724bd9-058a-428a-8052-67fb1eaf4e71",
    "_uuid": "9966ae6ab65c76abfa72e8d9503959a21665072d"
   },
   "source": [
    "The roc_auc in this case is about 0.95% with default hyperparameters. Let's try changing the hyperparameters - an exhaustive list of XGBoost hyperparameters is here: http://xgboost.readthedocs.io/en/latest/parameter.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2b2f8b31-33e9-454e-9393-263e628c3719",
    "_uuid": "309df6cbd77f3c31140606f4e0b620db53b87f35"
   },
   "source": [
    "Let's now try tuning the hyperparameters using k-fold CV. We'll then use grid search CV to find the optimal values of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "06427904-5c5e-4e36-bef9-1cf74e1be8c6",
    "_uuid": "7189e86b264593e6946cac56b267f38640257c49"
   },
   "outputs": [],
   "source": [
    "# hyperparameter tuning with XGBoost\n",
    "\n",
    "# creating a KFold object \n",
    "folds = 3\n",
    "\n",
    "# specify range of hyperparameters\n",
    "param_grid = {'learning_rate': [0.2, 0.6], \n",
    "             'subsample': [0.3, 0.6, 0.9]}          \n",
    "\n",
    "\n",
    "# specify model\n",
    "xgb_model = XGBClassifier(max_depth=2, n_estimators=200)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = xgb_model, \n",
    "                        param_grid = param_grid, \n",
    "                        scoring= 'roc_auc', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bfbc46d5-708a-477c-bd72-7722bf09e6ba",
    "_uuid": "dd828f9d6467b353a835f4163fcda0e6d662c24b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model_cv.fit(X_train, y_train)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f858e220-b38f-41e2-b083-06d8f5eb742b",
    "_uuid": "afd9d9144b8f8817cdc03b1a1f568f920650a48b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "332390e9-408e-433f-99fc-57e65c35b35e",
    "_uuid": "732bab662743e56fc8fe70c0930d3ce8ee25b126"
   },
   "outputs": [],
   "source": [
    "# convert parameters to int for plotting on x-axis\n",
    "cv_results['param_learning_rate'] = cv_results['param_learning_rate'].astype('float')\n",
    "cv_results['param_max_depth'] = cv_results['param_max_depth'].astype('float')\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fdb04f9e-4ada-4413-a8ae-a8bbb2cf2fac",
    "_uuid": "6e4a1bf2aea84e1361fd3234c228991273fa3ac5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "param_grid = {'learning_rate': [0.2, 0.6], \n",
    "             'subsample': [0.3, 0.6, 0.9]} \n",
    "\n",
    "\n",
    "for n, subsample in enumerate(param_grid['subsample']):\n",
    "    \n",
    "\n",
    "    # subplot 1/n\n",
    "    plt.subplot(1,len(param_grid['subsample']), n+1)\n",
    "    df = cv_results[cv_results['param_subsample']==subsample]\n",
    "\n",
    "    plt.plot(df[\"param_learning_rate\"], df[\"mean_test_score\"])\n",
    "    plt.plot(df[\"param_learning_rate\"], df[\"mean_train_score\"])\n",
    "    plt.xlabel('learning_rate')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.title(\"subsample={0}\".format(subsample))\n",
    "    plt.ylim([0.60, 1])\n",
    "    plt.legend(['test score', 'train score'], loc='upper left')\n",
    "    plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "21bd521a-86d8-4e42-8e98-c2bfb83f5248",
    "_uuid": "853a028f77dfabc43dc167b4cd92ca9418818106"
   },
   "source": [
    "The results show that a subsample size of 0.6 and learning_rate of about 0.2 seems optimal. \n",
    "Also, XGBoost has resulted in the highest ROC AUC obtained (across various hyperparameters). \n",
    "\n",
    "\n",
    "Let's build a final model with the chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f64f6dd4-1594-434d-b006-2607929c7848",
    "_uuid": "f6d26a03087caa6804c67bec109399f32a86e4fb"
   },
   "outputs": [],
   "source": [
    "# chosen hyperparameters\n",
    "# 'objective':'binary:logistic' outputs probability rather than label, which we need for auc\n",
    "params = {'learning_rate': 0.2,\n",
    "          'max_depth': 2, \n",
    "          'n_estimators':200,\n",
    "          'subsample':0.6,\n",
    "         'objective':'binary:logistic'}\n",
    "\n",
    "# fit model on training data\n",
    "model = XGBClassifier(params = params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4a8c73d2-d546-4741-9f81-99359a268e7d",
    "_uuid": "2bdcff9ae7faeeeac19bce56367f6f559fe9835e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = model.predict_proba(X_test)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "02d2e492-87ef-4eb8-b028-09089fbaae18",
    "_uuid": "072559ae029cf30f092bd89c571ac7e981e1a0bf"
   },
   "source": [
    "The first column in y_pred is the P(0), i.e. P(not fraud), and the second column is P(1/fraud)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fbf9a886-13ce-44f2-8489-7f903236f938",
    "_uuid": "fa63f1fa85a985837b2c77af4208b98522c86632",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# roc_auc\n",
    "auc = sklearn.metrics.roc_auc_score(y_test, y_pred[:, 1])\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's also look at the feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature importance\n",
    "importance = dict(zip(X_train.columns, model.feature_importances_))\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b753bc69-f824-4ed5-8f27-ec391f0cb820",
    "_uuid": "e02e3ccc572ac3bbcc9a40b8dd2bbe269a36994d"
   },
   "source": [
    "## Predictions on Test Data\n",
    "\n",
    "Since this problem is hosted on Kaggle, you can  choose to make predictions on the test data and submit your results. Please note the following points and recommendations if you go ahead with Kaggle:\n",
    "\n",
    "Recommendations for training:\n",
    "- We have used only a fraction of the training set (train_sample, 100k rows), the full training data on Kaggle (train.csv) has about 180 million rows. You'll get good results only if you train the model on a significant portion of the training dataset.  \n",
    "- Because of the size, you'll need to use Kaggle kernels to train the model on full training data. Kaggle kernels provide powerful computation capacities on cloud (for free). \n",
    "- Even on the kernel, you may need to use a portion of the training dataset (try using the last 20-30 million rows).\n",
    "- Make sure you save memory by following some tricks and best practices, else you won't be able to train the model at all on a large dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5532d104-b2a3-4495-a32d-d347055a8272",
    "_uuid": "73abe788098e03f5a103070bc06afa677f3bfb42",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # read submission file\n",
    "# sample_sub = pd.read_csv(path+'sample_submission.csv')\n",
    "# sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "91acaf2a-a44b-448b-86af-0781e889463b",
    "_uuid": "889d483f21d2dffc0c07cb9e6a3e3551eea121bb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # predict probability of test data\n",
    "# test_final = pd.read_csv(path+'test.csv')\n",
    "# test_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ba4edd78-5823-449d-a5a6-e55cde0057c0",
    "_uuid": "0e582de39d53048bdcb3b79a9b50a6afb5742966",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # predictions on test data\n",
    "# test_final = timeFeatures(test_final)\n",
    "# test_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "02bdddeb-9171-4a40-a110-eff2abee1239",
    "_uuid": "ada7e293edaa4772c49839701705e8da4fcc213f"
   },
   "outputs": [],
   "source": [
    "# test_final.drop(['click_time', 'datetime'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "825d147f-8447-4b67-be8f-e9980caaac97",
    "_uuid": "3492a7d7662192e1c71ccb4fb56aaee016aadbaa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bcbb019c-a5b7-4021-892d-d84c8b54f4de",
    "_uuid": "cb60a937abc73cadaf2cd49a3f91431bbeb31842"
   },
   "outputs": [],
   "source": [
    "# test_final[categorical_cols]=test_final[categorical_cols].apply(lambda x: le.fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "239a6d96-2477-45c3-98e1-d40d692ff082",
    "_uuid": "dfce41f901c260c41fbca0b4dc2eb2f2f7f58177"
   },
   "outputs": [],
   "source": [
    "# test_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5886ce06-1695-449f-8658-0aa1e5c7b010",
    "_uuid": "4d6d59acfd0c1e0164aa09deb902b3c912798b71",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # number of clicks by IP\n",
    "# ip_count = test_final.groupby('ip')['channel'].count().reset_index()\n",
    "# ip_count.columns = ['ip', 'count_by_ip']\n",
    "# ip_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f5288641-9582-469c-acd6-51513fd9a93c",
    "_uuid": "e93b28f1babd97189eaa659cf4ffdc43fdc58635",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge this with the training data\n",
    "# test_final = pd.merge(test_final, ip_count, on='ip', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "41d9f88a-3df5-4e6f-8afd-4fc52bbfb4ae",
    "_uuid": "53cdd133f981dbd14ee09e754b5af81a3a77b4a0"
   },
   "outputs": [],
   "source": [
    "# del ip_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6016b8ad-7d35-4837-85ac-3d42784ab6ea",
    "_uuid": "16f84bcaeac523300ad3e7abe3f5d21ce505804f"
   },
   "outputs": [],
   "source": [
    "# test_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "de511755-551a-44ac-9e77-513d2aa7b929",
    "_uuid": "3843d84a07dc833d877ec0d45b2239235b03c6cb"
   },
   "outputs": [],
   "source": [
    "# # predict on test data\n",
    "# y_pred_test = model.predict_proba(test_final.drop('click_id', axis=1))\n",
    "# y_pred_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "10bc9fae-f454-42b0-804e-cf883c7d98f7",
    "_uuid": "84b48e74756061d57921e7433fbbe3b4dca29490",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # # create submission file\n",
    "# sub = pd.DataFrame()\n",
    "# sub['click_id'] = test_final['click_id']\n",
    "# sub['is_attributed'] = y_pred_test[:, 1]\n",
    "# sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dfa37a2f-0a15-4be4-bcd8-1808a0fbfdc9",
    "_uuid": "a011efc336f0c2c88166554e82c12197b5121c96"
   },
   "outputs": [],
   "source": [
    "# sub.to_csv('kshitij_sub_03.csv', float_format='%.8f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b3b71dbe-b7ff-40bc-8262-cbde59c712f3",
    "_uuid": "f77f17efeb4fac255efde227f4eaa65a2c43e076"
   },
   "outputs": [],
   "source": [
    "# # model\n",
    "\n",
    "# dtrain = xgb.DMatrix(X_train, y_train)\n",
    "# del X_train, y_train\n",
    "# gc.collect()\n",
    "\n",
    "# watchlist = [(dtrain, 'train')]\n",
    "# model = xgb.train(params, dtrain, 30, watchlist, maximize=True, verbose_eval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "db49dcff-4c14-4f6d-b6cc-110b9ed1e47b",
    "_uuid": "6493db0e5e38a9481983babf3d64daf4fcace7e5"
   },
   "outputs": [],
   "source": [
    "# del dtrain\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fe8cbd2c-c1a3-4b8a-9275-8dff17e90f16",
    "_uuid": "38f4ee9799e8a04e7e7bdbe02f5841621f27927d"
   },
   "outputs": [],
   "source": [
    "# # Plot the feature importance from xgboost\n",
    "# plot_importance(model)\n",
    "# plt.gcf().savefig('feature_importance_xgb.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a8c6461b-5a4a-4b27-8f8e-e46a7ffd0e5b",
    "_uuid": "83d484fa2e3077b118c5146e6c3c58b54b8c75a0"
   },
   "outputs": [],
   "source": [
    "# # Load the test for predict \n",
    "# test = pd.read_csv(path+\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "090a2f56-026a-4376-b071-161a6863d25d",
    "_uuid": "e96efa999cbf63e6c07d9769b99ca1f064a1612c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ad5bbd29-e6f9-4952-a23f-7598d8d9c94d",
    "_uuid": "a1a061bc835ae785c7443e8779a9e141f239693e"
   },
   "outputs": [],
   "source": [
    "# # number of clicks by IP\n",
    "# ip_count = train_sample.groupby('ip')['channel'].count().reset_index()\n",
    "# ip_count.columns = ['ip', 'count_by_ip']\n",
    "# ip_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "95b5cedc-5165-4c7e-867b-dab3e46ca3e2",
    "_uuid": "50aae38136a666d034f7060b5e54e99a0abb7adb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test = pd.merge(test, ip_count, on='ip', how='left', sort=False)\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9324f06c-96e1-4ebd-bb30-f9e88ca6b4ce",
    "_uuid": "d698400a78a8c8843b4e04c9d47767594b214caf"
   },
   "outputs": [],
   "source": [
    "# test = timeFeatures(test)\n",
    "# test.drop(['click_time', 'datetime'], axis=1, inplace=True)\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b8f94753-e35b-4c10-a435-e81daec0759e",
    "_uuid": "f21d987e6c926f51ab6d48158eaeed87d26d4d15",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(test.columns)\n",
    "# print(train_sample.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fad3b6a8-c5db-4424-9325-5e8a94b04b7a",
    "_uuid": "890843c2bde74b1f3ea4a7409aaa656647f43bbc"
   },
   "outputs": [],
   "source": [
    "# test = test[['click_id','ip', 'app', 'device', 'os', 'channel', 'day_of_week',\n",
    "#        'day_of_year', 'month', 'hour', 'count_by_ip']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b4aa9652-7cf0-4977-9f56-b1db67487fe3",
    "_uuid": "0358f7fb017d39148f93d31f616cdbaf9a5909b2"
   },
   "outputs": [],
   "source": [
    "# dtest = xgb.DMatrix(test.drop('click_id', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "42ef6682-b06a-4959-8a09-4c57ef9f8c7d",
    "_uuid": "1c4ebd9c9c5ad26dcd13dcc4f47c96c817971f76"
   },
   "outputs": [],
   "source": [
    "# # Save the predictions\n",
    "# sub = pd.DataFrame()\n",
    "# sub['click_id'] = test['click_id']\n",
    "\n",
    "# sub['is_attributed'] = model.predict(dtest, ntree_limit=model.best_ntree_limit)\n",
    "# sub.to_csv('xgb_sub.csv', float_format='%.8f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0279f64a-361e-4f29-8eb6-40b0891d25a9",
    "_uuid": "47d4428933ebd21a5ce09c31d09e8b2fc9760270"
   },
   "outputs": [],
   "source": [
    "# sub.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
