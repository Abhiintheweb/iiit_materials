{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Credit Default Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will build a random forest model to predict whether a given customer defaults or not. Credit default is one of the most important problems in the banking and risk analytics industry. There are various attributes which can be used to predict default, such as demographic data (age, income, employment status, etc.), (credit) behavioural data (past loans, payment, number of times a credit payment has been delayed by the customer etc.).\n",
    "\n",
    "We'll start the process with data cleaning and preparation and then tune the model to find optimal hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>defaulted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "1   2     120000    2          2         2   26     -1      2      0      0   \n",
       "2   3      90000    2          2         2   34      0      0      0      0   \n",
       "3   4      50000    2          2         1   37      0      0      0      0   \n",
       "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "     ...      BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0    ...              0          0          0         0       689         0   \n",
       "1    ...           3272       3455       3261         0      1000      1000   \n",
       "2    ...          14331      14948      15549      1518      1500      1000   \n",
       "3    ...          28314      28959      29547      2000      2019      1200   \n",
       "4    ...          20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  defaulted  \n",
       "0         0         0         0          1  \n",
       "1      1000         0      2000          1  \n",
       "2      1000      1000      5000          0  \n",
       "3      1100      1069      1000          0  \n",
       "4      9000       689       679          0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the csv file and putting it into 'df' object.\n",
    "df = pd.read_csv('credit-card-default.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 25 columns):\n",
      "ID           30000 non-null int64\n",
      "LIMIT_BAL    30000 non-null int64\n",
      "SEX          30000 non-null int64\n",
      "EDUCATION    30000 non-null int64\n",
      "MARRIAGE     30000 non-null int64\n",
      "AGE          30000 non-null int64\n",
      "PAY_0        30000 non-null int64\n",
      "PAY_2        30000 non-null int64\n",
      "PAY_3        30000 non-null int64\n",
      "PAY_4        30000 non-null int64\n",
      "PAY_5        30000 non-null int64\n",
      "PAY_6        30000 non-null int64\n",
      "BILL_AMT1    30000 non-null int64\n",
      "BILL_AMT2    30000 non-null int64\n",
      "BILL_AMT3    30000 non-null int64\n",
      "BILL_AMT4    30000 non-null int64\n",
      "BILL_AMT5    30000 non-null int64\n",
      "BILL_AMT6    30000 non-null int64\n",
      "PAY_AMT1     30000 non-null int64\n",
      "PAY_AMT2     30000 non-null int64\n",
      "PAY_AMT3     30000 non-null int64\n",
      "PAY_AMT4     30000 non-null int64\n",
      "PAY_AMT5     30000 non-null int64\n",
      "PAY_AMT6     30000 non-null int64\n",
      "defaulted    30000 non-null int64\n",
      "dtypes: int64(25)\n",
      "memory usage: 5.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Let's understand the type of columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we know that there are no major data quality issues, so we'll go ahead and build the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation and Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing test_train_split from sklearn library\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "X = df.drop('defaulted',axis=1)\n",
    "\n",
    "# Putting response variable to y\n",
    "y = df['defaulted']\n",
    "\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Default Hyperparameters\n",
    "Let's first fit a random forest model with default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing random forest classifier from sklearn library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Running the random forest with default parameters.\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing classification report and confusion matrix from sklearn metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89      7058\n",
      "          1       0.62      0.32      0.42      1942\n",
      "\n",
      "avg / total       0.79      0.81      0.79      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check the report of our default model\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6683  375]\n",
      " [1318  624]]\n"
     ]
    }
   ],
   "source": [
    "# Printing confusion matrix\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8118888888888889\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good, let's now look at the list of hyperparameters which we can tune to improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following hyperparameters are present in a random forest classifier. Note that most of these hypereparameters are actually of the decision trees that are in the forest.\n",
    "\n",
    "\n",
    "- **n_estimators**: integer, optional (default=10): The number of trees in the forest.\n",
    "- **criterion**: string, optional (default=”gini”)The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Note: this parameter is tree-specific.\n",
    "- **max_features** : int, float, string or None, optional (default=”auto”)The number of features to consider when looking for the best split:\n",
    "    - If int, then consider max_features features at each split.\n",
    "    - If float, then max_features is a percentage and int(max_features * n_features) features are considered at each split.\n",
    "    - If “auto”, then max_features=sqrt(n_features).\n",
    "    - If “sqrt”, then max_features=sqrt(n_features) (same as “auto”).\n",
    "    - If “log2”, then max_features=log2(n_features).\n",
    "    - If None, then max_features=n_features.\n",
    "    - Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.\n",
    "- **max_depth** : integer or None, optional (default=None)The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "- **min_samples_split** : int, float, optional (default=2)The minimum number of samples required to split an internal node:**\n",
    "    - **If int, then consider min_samples_split as the minimum number.\n",
    "    - **If float, then min_samples_split is a percentage and ceil(min_samples_split, n_samples) are the minimum number of samples for each split.\n",
    "- **min_samples_leaf** : int, float, optional (default=1)The minimum number of samples required to be at a leaf node:**\n",
    "    - **If int, then consider min_samples_leaf as the minimum number.**\n",
    "    - **If float, then min_samples_leaf is a percentage and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.**\n",
    "- **min_weight_fraction_leaf** : float, optional (default=0.)The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.\n",
    "- **max_leaf_nodes** : int or None, optional (default=None)Grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.\n",
    "- **min_impurity_split** : float,Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find the optimum values for ```max_depth``` and understand how the value of max_depth impacts the overall accuracy of the ensemble.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [2, 7, 12, 17]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='accuracy',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV to find optimal n_estimators\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_depth': range(2, 20, 5)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.090936</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.799322</td>\n",
       "      <td>2</td>\n",
       "      <td>{u'max_depth': 2}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.808379</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.799048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.795536</td>\n",
       "      <td>0.794524</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>0.794475</td>\n",
       "      <td>0.795905</td>\n",
       "      <td>0.010239</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.005374</td>\n",
       "      <td>0.003986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.219714</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>0.812857</td>\n",
       "      <td>0.828440</td>\n",
       "      <td>7</td>\n",
       "      <td>{u'max_depth': 7}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.813378</td>\n",
       "      <td>0.829573</td>\n",
       "      <td>0.814048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813810</td>\n",
       "      <td>0.827619</td>\n",
       "      <td>0.813571</td>\n",
       "      <td>0.830655</td>\n",
       "      <td>0.809478</td>\n",
       "      <td>0.829296</td>\n",
       "      <td>0.023150</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.001951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.289510</td>\n",
       "      <td>0.005753</td>\n",
       "      <td>0.811238</td>\n",
       "      <td>0.878595</td>\n",
       "      <td>12</td>\n",
       "      <td>{u'max_depth': 12}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.811711</td>\n",
       "      <td>0.876778</td>\n",
       "      <td>0.815476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810952</td>\n",
       "      <td>0.878214</td>\n",
       "      <td>0.807619</td>\n",
       "      <td>0.880893</td>\n",
       "      <td>0.810431</td>\n",
       "      <td>0.878460</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.001322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.365143</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>0.807190</td>\n",
       "      <td>0.924595</td>\n",
       "      <td>17</td>\n",
       "      <td>{u'max_depth': 17}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.809569</td>\n",
       "      <td>0.921722</td>\n",
       "      <td>0.807381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.927381</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>0.925476</td>\n",
       "      <td>0.807811</td>\n",
       "      <td>0.924588</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.001866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.090936         0.003082         0.800000          0.799322   \n",
       "1       0.219714         0.004565         0.812857          0.828440   \n",
       "2       0.289510         0.005753         0.811238          0.878595   \n",
       "3       0.365143         0.007854         0.807190          0.924595   \n",
       "\n",
       "  param_max_depth              params  rank_test_score  split0_test_score  \\\n",
       "0               2   {u'max_depth': 2}                4           0.808379   \n",
       "1               7   {u'max_depth': 7}                1           0.813378   \n",
       "2              12  {u'max_depth': 12}                2           0.811711   \n",
       "3              17  {u'max_depth': 17}                3           0.809569   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0            0.806000           0.799048       ...                  0.803571   \n",
       "1            0.829573           0.814048       ...                  0.813810   \n",
       "2            0.876778           0.815476       ...                  0.810952   \n",
       "3            0.921722           0.807381       ...                  0.809524   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.795536           0.794524            0.801667   \n",
       "1            0.827619           0.813571            0.830655   \n",
       "2            0.878214           0.807619            0.880893   \n",
       "3            0.927381           0.801667            0.925476   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.794475            0.795905      0.010239        0.000673   \n",
       "1           0.809478            0.829296      0.023150        0.000462   \n",
       "2           0.810431            0.878460      0.004576        0.000069   \n",
       "3           0.807811            0.924588      0.007338        0.001068   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.005374         0.003986  \n",
       "1        0.001704         0.001951  \n",
       "2        0.002530         0.001322  \n",
       "3        0.002900         0.001866  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that as we increase the value of max_depth, both train and test scores increase till a point, but after that test score starts to decrease. The ensemble tries to overfit as we increase the max_depth.\n",
    "\n",
    "Thus, controlling the depth of the constituent trees will help reduce overfitting in the forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find the optimum values for n_estimators and understand how the value of n_estimators impacts the overall accuracy. Notice that we'll specify an appropriately low value of max_depth, so that the trees do not overfit.\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GridSearchCV to find optimal n_estimators\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'n_estimators': range(100, 1500, 400)}\n",
    "\n",
    "# instantiate the model (note we are specifying a max_depth)\n",
    "rf = RandomForestClassifier(max_depth=4)\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting accuracies with n_estimators\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max_features\n",
    "\n",
    "Let's see how the model performance varies with ```max_features```, which is the maximum numbre of features considered for splitting at a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV to find optimal max_features\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_features': [4, 8, 14, 20, 24]}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(max_depth=4)\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting accuracies with max_features\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the training and test scores *both* seem to increase as we increase max_features, and the model doesn't seem to overfit more with increasing max_features. Think about why that might be the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning min_samples_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter **min_samples_leaf** is the minimum number of samples required to be at a leaf node:\n",
    "- If int, then consider min_samples_leaf as the minimum number.\n",
    "- If float, then min_samples_leaf is a percentage and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check the optimum value for min samples leaf in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV to find optimal min_samples_leaf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_leaf': range(100, 400, 50)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting accuracies with min_samples_leaf\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the model starts of overfit as you decrease the value of min_samples_leaf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning min_samples_split\n",
    "\n",
    "Let's now look at the performance of the ensemble as we vary min_samples_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GridSearchCV to find optimal min_samples_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_split': range(200, 500, 50)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting accuracies with min_samples_split\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search to Find Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now find the optimal hyperparameters using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [4,8,10],\n",
    "    'min_samples_leaf': range(100, 400, 200),\n",
    "    'min_samples_split': range(200, 500, 200),\n",
    "    'n_estimators': [100,200, 300], \n",
    "    'max_features': [5, 10]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "print('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting the final model with the best parameters obtained from grid search.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with the best hyperparameters\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(bootstrap=True,\n",
    "                             max_depth=10,\n",
    "                             min_samples_leaf=100, \n",
    "                             min_samples_split=200,\n",
    "                             max_features=10,\n",
    "                             n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
