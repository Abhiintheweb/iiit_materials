{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Telecom Churn: Logistic Regression with PCA\n",
    "\n",
    "With 21 predictor variables, we need to predict whether a particular customer will switch to another telecom provider or not. In telecom terminology, customer attrition is referred to as 'churn'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Merging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas and NumPy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all datasets\n",
    "churn_data = pd.read_csv(\"churn_data.csv\")\n",
    "customer_data = pd.read_csv(\"customer_data.csv\")\n",
    "internet_data = pd.read_csv(\"internet_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7043\n",
      "7043\n",
      "7043\n"
     ]
    }
   ],
   "source": [
    "print(len(churn_data))\n",
    "print(len(customer_data))\n",
    "print(len(internet_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging on 'customerID'\n",
    "df_1 = pd.merge(churn_data, customer_data, how='inner', on='customerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final dataframe with all predictor variables\n",
    "telecom = pd.merge(df_1, internet_data, how='inner', on='customerID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's understand the structure of our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>gender</th>\n",
       "      <th>...</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  tenure PhoneService        Contract PaperlessBilling  \\\n",
       "0  7590-VHVEG       1           No  Month-to-month              Yes   \n",
       "1  5575-GNVDE      34          Yes        One year               No   \n",
       "2  3668-QPYBK       2          Yes  Month-to-month              Yes   \n",
       "3  7795-CFOCW      45           No        One year               No   \n",
       "4  9237-HQITU       2          Yes  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod  MonthlyCharges TotalCharges Churn  gender  \\\n",
       "0           Electronic check           29.85        29.85    No  Female   \n",
       "1               Mailed check           56.95       1889.5    No    Male   \n",
       "2               Mailed check           53.85       108.15   Yes    Male   \n",
       "3  Bank transfer (automatic)           42.30      1840.75    No    Male   \n",
       "4           Electronic check           70.70       151.65   Yes  Female   \n",
       "\n",
       "        ...        Partner Dependents     MultipleLines InternetService  \\\n",
       "0       ...            Yes         No  No phone service             DSL   \n",
       "1       ...             No         No                No             DSL   \n",
       "2       ...             No         No                No             DSL   \n",
       "3       ...             No         No  No phone service             DSL   \n",
       "4       ...             No         No                No     Fiber optic   \n",
       "\n",
       "  OnlineSecurity OnlineBackup DeviceProtection TechSupport StreamingTV  \\\n",
       "0             No          Yes               No          No          No   \n",
       "1            Yes           No              Yes          No          No   \n",
       "2            Yes          Yes               No          No          No   \n",
       "3            Yes           No              Yes         Yes          No   \n",
       "4             No           No               No          No          No   \n",
       "\n",
       "  StreamingMovies  \n",
       "0              No  \n",
       "1              No  \n",
       "2              No  \n",
       "3              No  \n",
       "4              No  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the head of our master dataset\n",
    "telecom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7043.000000</td>\n",
       "      <td>7043.000000</td>\n",
       "      <td>7043.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.371149</td>\n",
       "      <td>64.761692</td>\n",
       "      <td>0.162147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.559481</td>\n",
       "      <td>30.090047</td>\n",
       "      <td>0.368612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>70.350000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>89.850000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>118.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tenure  MonthlyCharges  SeniorCitizen\n",
       "count  7043.000000     7043.000000    7043.000000\n",
       "mean     32.371149       64.761692       0.162147\n",
       "std      24.559481       30.090047       0.368612\n",
       "min       0.000000       18.250000       0.000000\n",
       "25%       9.000000       35.500000       0.000000\n",
       "50%      29.000000       70.350000       0.000000\n",
       "75%      55.000000       89.850000       0.000000\n",
       "max      72.000000      118.750000       1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Yes to 1 and No to 0\n",
    "telecom['PhoneService'] = telecom['PhoneService'].map({'Yes': 1, 'No': 0})\n",
    "telecom['PaperlessBilling'] = telecom['PaperlessBilling'].map({'Yes': 1, 'No': 0})\n",
    "telecom['Churn'] = telecom['Churn'].map({'Yes': 1, 'No': 0})\n",
    "telecom['Partner'] = telecom['Partner'].map({'Yes': 1, 'No': 0})\n",
    "telecom['Dependents'] = telecom['Dependents'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Variable Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dummy variable for the variable 'Contract' and dropping the first one.\n",
    "cont = pd.get_dummies(telecom['Contract'],prefix='Contract',drop_first=True)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,cont],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'PaymentMethod' and dropping the first one.\n",
    "pm = pd.get_dummies(telecom['PaymentMethod'],prefix='PaymentMethod',drop_first=True)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,pm],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'gender' and dropping the first one.\n",
    "gen = pd.get_dummies(telecom['gender'],prefix='gender',drop_first=True)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,gen],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'MultipleLines' and dropping the first one.\n",
    "ml = pd.get_dummies(telecom['MultipleLines'],prefix='MultipleLines')\n",
    "#  dropping MultipleLines_No phone service column\n",
    "ml1 = ml.drop(['MultipleLines_No phone service'],1)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,ml1],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'InternetService' and dropping the first one.\n",
    "iser = pd.get_dummies(telecom['InternetService'],prefix='InternetService',drop_first=True)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,iser],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'OnlineSecurity'.\n",
    "os = pd.get_dummies(telecom['OnlineSecurity'],prefix='OnlineSecurity')\n",
    "os1= os.drop(['OnlineSecurity_No internet service'],1)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,os1],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'OnlineBackup'.\n",
    "ob =pd.get_dummies(telecom['OnlineBackup'],prefix='OnlineBackup')\n",
    "ob1 =ob.drop(['OnlineBackup_No internet service'],1)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,ob1],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'DeviceProtection'. \n",
    "dp =pd.get_dummies(telecom['DeviceProtection'],prefix='DeviceProtection')\n",
    "dp1 = dp.drop(['DeviceProtection_No internet service'],1)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,dp1],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'TechSupport'. \n",
    "ts =pd.get_dummies(telecom['TechSupport'],prefix='TechSupport')\n",
    "ts1 = ts.drop(['TechSupport_No internet service'],1)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,ts1],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'StreamingTV'.\n",
    "st =pd.get_dummies(telecom['StreamingTV'],prefix='StreamingTV')\n",
    "st1 = st.drop(['StreamingTV_No internet service'],1)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,st1],axis=1)\n",
    "\n",
    "# Creating a dummy variable for the variable 'StreamingMovies'. \n",
    "sm =pd.get_dummies(telecom['StreamingMovies'],prefix='StreamingMovies')\n",
    "sm1 = sm.drop(['StreamingMovies_No internet service'],1)\n",
    "#Adding the results to the master dataframe\n",
    "telecom = pd.concat([telecom,sm1],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping the repeated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have created dummies for the below variables, so we can drop them\n",
    "telecom = telecom.drop(['Contract','PaymentMethod','gender','MultipleLines','InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "       'TechSupport', 'StreamingTV', 'StreamingMovies'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhi/venvs/notebook/lib/python2.7/site-packages/ipykernel_launcher.py:2: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#The varaible was imported as a string we need to convert it to float\n",
    "telecom['TotalCharges'] =telecom['TotalCharges'].convert_objects(convert_numeric=True)\n",
    "#telecom['tenure'] = telecom['tenure'].astype(int).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see we have all variables as integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Checking for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for outliers in the continuous variables\n",
    "num_telecom = telecom[['tenure','MonthlyCharges','SeniorCitizen','TotalCharges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking outliers at 25%,50%,75%,90%,95% and 99%\n",
    "num_telecom.describe(percentiles=[.25,.5,.75,.90,.95,.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the distribution shown above, you can see that there no outliner in your data. The numbers are gradually increasing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Missing Values and Inputing Them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It means that 11/7043 = 0.001561834 i.e 0.1%, best is to remove these observations from the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the percentage of missing values\n",
    "100*(telecom.isnull().sum()/len(telecom.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing NaN TotalCharges rows\n",
    "telecom = telecom[~np.isnan(telecom['TotalCharges'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*(telecom.isnull().sum()/len(telecom.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we don't have any missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising continuous features\n",
    "df = telecom[['tenure','MonthlyCharges','TotalCharges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df=(df-df.mean())/df.std()\n",
    "telecom = telecom.drop(['tenure','MonthlyCharges','TotalCharges'], 1)\n",
    "telecom = pd.concat([telecom,normalized_df],axis=1)\n",
    "telecom.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Churn Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = (sum(telecom['Churn'])/len(telecom['Churn'].index))*100\n",
    "churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have almost 27% churn rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "Let's start by splitting our data into a training set and a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Putting feature variable to X\n",
    "X = telecom.drop(['Churn','customerID'],axis=1)\n",
    "\n",
    "# Putting response variable to y\n",
    "y = telecom['Churn']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Your First Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "logm1.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing matplotlib and seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the correlation matrix \n",
    "plt.figure(figsize = (20,10))        # Size of the figure\n",
    "sns.heatmap(telecom.corr(),annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping highly correlated variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = X_test.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No','StreamingTV_No','StreamingMovies_No'],1)\n",
    "X_train2 = X_train.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No','StreamingTV_No','StreamingMovies_No'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Correlation Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping highly correlated variables now let's check the correlation matrix again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "sns.heatmap(X_train2.corr(),annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Running the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run our model again after dropping highly correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm2 = sm.GLM(y_train,(sm.add_constant(X_train2)), family = sm.families.Binomial())\n",
    "logm2.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(logreg, 13)             # running RFE with 13 variables as output\n",
    "rfe = rfe.fit(X,y)\n",
    "print(rfe.support_)           # Printing the boolean results\n",
    "print(rfe.ranking_)           # Printing the ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables selected by RFE \n",
    "col = ['PhoneService', 'PaperlessBilling', 'Contract_One year', 'Contract_Two year',\n",
    "       'PaymentMethod_Electronic check','MultipleLines_No','InternetService_Fiber optic', 'InternetService_No',\n",
    "       'OnlineSecurity_Yes','TechSupport_Yes','StreamingMovies_No','tenure','TotalCharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run the model using the selected variables\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "logsk = LogisticRegression(C=1e9)\n",
    "#logsk.fit(X_train[col], y_train)\n",
    "logsk.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the model with StatsModels\n",
    "#logm4 = sm.GLM(y_train,(sm.add_constant(X_train[col])), family = sm.families.Binomial())\n",
    "logm4 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "modres = logm4.fit()\n",
    "logm4.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[col].shape\n",
    "#res = modres.predict(X_test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted probabilities\n",
    "y_pred = logsk.predict_proba(X_test)\n",
    "# Converting y_pred to a dataframe which is an array\n",
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "# Converting to column dataframe\n",
    "y_pred_1 = y_pred_df.iloc[:,[1]]\n",
    "# Let's see the head\n",
    "y_pred_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting CustID to index\n",
    "y_test_df['CustID'] = y_test_df.index\n",
    "# Removing index for both dataframes to append them side by side \n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)\n",
    "# Appending y_test_df and y_pred_1\n",
    "y_pred_final = pd.concat([y_test_df,y_pred_1],axis=1)\n",
    "# Renaming the column \n",
    "y_pred_final= y_pred_final.rename(columns={ 1 : 'Churn_Prob'})\n",
    "# Rearranging the columns\n",
    "y_pred_final = y_pred_final.reindex_axis(['CustID','Churn','Churn_Prob'], axis=1)\n",
    "# Let's see the head of y_pred_final\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new column 'predicted' with 1 if Churn_Prob>0.5 else 0\n",
    "y_pred_final['predicted'] = y_pred_final.Churn_Prob.map( lambda x: 1 if x > 0.5 else 0)\n",
    "# Let's see the head\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "confusion = metrics.confusion_matrix( y_pred_final.Churn, y_pred_final.predicted )\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted     Churn  not_churn  __all__\n",
    "# Actual\n",
    "# Churn            1359   169     1528\n",
    "# not_churn         256   326      582\n",
    "# __all__          1615   751     2110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check the overall accuracy.\n",
    "metrics.accuracy_score(y_pred_final.Churn, y_pred_final.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return fpr, tpr, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc(y_pred_final.Churn, y_pred_final.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw_roc(y_pred_final.Churn, y_pred_final.predicted)\n",
    "\"{:2.2f}\".format(metrics.roc_auc_score(y_pred_final.Churn, y_pred_final.Churn_Prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see an overall AUC score of 0.83 looks like we did a decent job.\n",
    "- But we did spend a lot of effort on the features and their selection.\n",
    "- Can PCA help reduce our effort?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note - \n",
    "- While computng the principal components, we must not include the entire dataset. Model building is all about doing well on the data we haven't seen yet!\n",
    "- So we'll calculate the PCs using the train data, and apply them later on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "# We have 30 variables after creating our dummy variables for our categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improting the PCA module\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(svd_solver='randomized', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing the PCA on the train data\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's plot the principal components and try to make sense of them\n",
    "- We'll plot original features on the first 2 principal components as axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = list(X_train.columns)\n",
    "pcs_df = pd.DataFrame({'PC1':pca.components_[0],'PC2':pca.components_[1], 'Feature':colnames})\n",
    "pcs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "plt.scatter(pcs_df.PC1, pcs_df.PC2)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "for i, txt in enumerate(pcs_df.Feature):\n",
    "    plt.annotate(txt, (pcs_df.PC1[i],pcs_df.PC2[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the fist component is in the direction where the 'charges' variables are heavy\n",
    " - These 3 components also have the highest of the loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the screeplot to assess the number of needed principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the screeplot - plotting the cumulative variance against the number of components\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like 16 components are enough to describe 95% of the variance in the dataset\n",
    "- We'll choose 16 components for our modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using incremental PCA for efficiency - saves a lot of time on larger datasets\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "pca_final = IncrementalPCA(n_components=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basis transformation - getting the data onto our PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_pca = pca_final.fit_transform(X_train)\n",
    "df_train_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating correlation matrix for the principal components - we expect little to no correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating correlation matrix for the principal components\n",
    "corrmat = np.corrcoef(df_train_pca.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotting the correlation matrix\n",
    "%matplotlib inline\n",
    "plt.figure(figsize = (20,10))\n",
    "sns.heatmap(corrmat,annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1s -> 0s in diagonals\n",
    "corrmat_nodiag = corrmat - np.diagflat(corrmat.diagonal())\n",
    "print(\"max corr:\",corrmat_nodiag.max(), \", min corr: \", corrmat_nodiag.min(),)\n",
    "# we see that correlations are indeed very close to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indeed - there is no correlation between any two components! Good job, PCA!\n",
    "- We effectively have removed multicollinearity from our situation, and our models will be much more stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying selected components to the test data - 16 components\n",
    "df_test_pca = pca_final.transform(X_test)\n",
    "df_test_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying a logistic regression on our Principal Components\n",
    "- We expect to get similar model performance with significantly lower features\n",
    "- If we can do so, we would have done effective dimensionality reduction without losing any import information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model on the train data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "learner_pca = LogisticRegression()\n",
    "model_pca = learner_pca.fit(df_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "Note that we are fitting the original variable y with the transformed variables (principal components). This is not a problem becuase the transformation done in PCA is *linear*, which implies that you've only changed the way the new x variables are represented, though the nature of relationship between X and Y is still linear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making prediction on the test data\n",
    "pred_probs_test = model_pca.predict_proba(df_test_pca)[:,1]\n",
    "\"{:2.2}\".format(metrics.roc_auc_score(y_test, pred_probs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impressive! The same result, without all the hard work on feature selection!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why not take it a step further and get a little more 'unsupervised' in our approach?\n",
    "This time, we'll let PCA select the number of components basen on a variance cutoff we provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_again = PCA(0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pca2 = pca_again.fit_transform(X_train)\n",
    "df_train_pca2.shape\n",
    "# we see that PCA selected 14 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the regression model\n",
    "learner_pca2 = LogisticRegression()\n",
    "model_pca2 = learner_pca2.fit(df_train_pca2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pca2 = pca_again.transform(X_test)\n",
    "df_test_pca2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making prediction on the test data\n",
    "pred_probs_test2 = model_pca2.predict_proba(df_test_pca2)[:,1]\n",
    "\"{:2.2f}\".format(metrics.roc_auc_score(y_test, pred_probs_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So there it is - a very similar result, without all the hassles. We have not only achieved dimensionality reduction, but also saved a lot of effort on feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before closing, let's also visualize the data to see if we can spot any patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "plt.scatter(df_train_pca[:,0], df_train_pca[:,1], c = y_train.map({0:'green',1:'red'}))\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there is a good amount of separation in 2D, but probably not enough\n",
    "\n",
    "Let's look at it in 3D, and we expect spread to be better (dimensions of variance, remember?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = Axes3D(fig)\n",
    "# ax = plt.axes(projection='3d')\n",
    "ax.scatter(df_train_pca[:,2], df_train_pca[:,0], df_train_pca[:,1], c=y_train.map({0:'green',1:'red'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So let's try building the model with just 3 principal components!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_last = PCA(n_components=3)\n",
    "df_train_pca3 = pca_last.fit_transform(X_train)\n",
    "df_test_pca3 = pca_last.transform(X_test)\n",
    "df_test_pca3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training the regression model\n",
    "learner_pca3 = LogisticRegression()\n",
    "model_pca3 = learner_pca3.fit(df_train_pca3,y_train)\n",
    "#Making prediction on the test data\n",
    "pred_probs_test3 = model_pca3.predict_proba(df_test_pca3)[:,1]\n",
    "\"{:2.2f}\".format(metrics.roc_auc_score(y_test, pred_probs_test3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.82! Isn't that just amazing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
