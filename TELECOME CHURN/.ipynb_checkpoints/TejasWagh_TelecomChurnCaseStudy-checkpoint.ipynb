{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telecom Churn Case study\n",
    "\n",
    "### Group Members:\n",
    "- __Tejas Wagh(Group facilitator)__\n",
    "- __Pawan Tejwani__\n",
    "- __Dr.Sandeep Patil __\n",
    "- __Abhishek Singh __\n",
    "\n",
    "\n",
    "\n",
    "#### We have represented case study in the following format:\n",
    "- Data Cleaning and Formatting\n",
    "- EDA\n",
    "- PCA and logistic regression for predicting customers who are going to churn.\n",
    "- Tree models for identifying important indicators in predicting customers who are going to churn.\n",
    "- Final report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading https://files.pythonhosted.org/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/63/416529a405262610350b92b949b3aede55a032e4f5ab94fbbfce82883ee6/imbalanced-learn-0.3.3.tar.gz (41.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 41.9MB 229kB/s ta 0:00:014\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/abhi/venvs/notebook/lib/python2.7/site-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
      "Requirement already satisfied: numpy in /home/abhi/venvs/notebook/lib/python2.7/site-packages (from imbalanced-learn->imblearn) (1.14.5)\n",
      "Requirement already satisfied: scikit-learn in /home/abhi/venvs/notebook/lib/python2.7/site-packages (from imbalanced-learn->imblearn) (0.19.1)\n",
      "Building wheels for collected packages: imbalanced-learn\n",
      "  Running setup.py bdist_wheel for imbalanced-learn ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/abhi/.cache/pip/wheels/f4/a9/be/363d606aab48a47f91b3c5aadfbe0e8eb78974997e38a2c7ce\n",
      "Successfully built imbalanced-learn\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.3.3 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "!pip install imblearn\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom = pd.read_csv('telecom_churn_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "telecom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(telecom['total_rech_amt_6'].isnull().sum(),telecom['total_rech_amt_7'].isnull().sum(), telecom['total_rech_data_6'].isnull().sum(), telecom['total_rech_data_7'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Imputing missing values\n",
    "\n",
    "telecom['total_rech_data_6'].fillna(0, inplace=True)\n",
    "telecom['total_rech_data_7'].fillna(0, inplace=True)\n",
    "telecom['total_rech_data_8'].fillna(0, inplace=True)\n",
    "telecom['total_rech_data_9'].fillna(0, inplace=True)\n",
    "telecom['av_rech_amt_data_6'].fillna(0, inplace=True)\n",
    "telecom['av_rech_amt_data_7'].fillna(0, inplace=True)\n",
    "telecom['av_rech_amt_data_8'].fillna(0, inplace=True)\n",
    "telecom['av_rech_amt_data_9'].fillna(0, inplace=True)\n",
    "telecom['max_rech_data_6'].fillna(0, inplace=True)\n",
    "telecom['max_rech_data_7'].fillna(0, inplace=True)\n",
    "telecom['max_rech_data_8'].fillna(0, inplace=True)\n",
    "telecom['max_rech_data_9'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "telecom['night_pck_user_6'].fillna(-1, inplace=True)\n",
    "telecom['night_pck_user_7'].fillna(-1, inplace=True)\n",
    "telecom['night_pck_user_8'].fillna(-1, inplace=True)\n",
    "telecom['night_pck_user_9'].fillna(-1, inplace=True)\n",
    "telecom['fb_user_6'].fillna(-1, inplace=True)\n",
    "telecom['fb_user_7'].fillna(-1, inplace=True)\n",
    "telecom['fb_user_8'].fillna(-1, inplace=True)\n",
    "telecom['fb_user_9'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom['total_rech_amt_data_6'] = telecom['total_rech_data_6'] * telecom['av_rech_amt_data_6']\n",
    "telecom['total_rech_amt_data_7'] = telecom['total_rech_data_7'] * telecom['av_rech_amt_data_7']\n",
    "telecom['total_rech_amt_data_8'] = telecom['total_rech_data_8'] * telecom['av_rech_amt_data_8']\n",
    "telecom['total_rech_amt_data_9'] = telecom['total_rech_data_9'] * telecom['av_rech_amt_data_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As per problem statement creating a column of average recharge amount of first two months\n",
    "telecom['avg_rech_amt'] = ((telecom['total_rech_amt_6'] + telecom['total_rech_amt_data_6']) + (telecom['total_rech_amt_7'] + telecom['total_rech_amt_data_7']))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As per problem statement creating dataframe which has only customers with average recharge amount more than or equal to 70th percentile of average recharge amount \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = telecom.avg_rech_amt.quantile(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom = telecom[telecom.avg_rech_amt >= Q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom['churn'] = np.where(((telecom['total_ic_mou_9']==0) & (telecom['total_og_mou_9']==0)) & ((telecom['vol_2g_mb_9']==0) & (telecom['vol_3g_mb_9']==0)),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns with '_9' at the end\n",
    "new_col = [c for c in telecom.columns if c[-2:] != '_9']\n",
    "telecom = telecom[new_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking percentage missing values in each columns\n",
    "round(100*(telecom.isnull().sum()/len(telecom.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(round(100*(telecom.isnull().sum()/len(telecom.index))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns which have more than 50% NaN values\n",
    "for cl in telecom.columns:\n",
    "    if round(100*(telecom[cl].isnull().sum()/len(telecom[cl].index)), 2) > 40:\n",
    "        telecom = telecom.drop(cl, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(100*(telecom.isnull().sum()/len(telecom.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_4=[]\n",
    "for cl in telecom.columns:\n",
    "    if 2<round(100*(telecom[cl].isnull().sum()/len(telecom[cl].index)), 2)<5 :\n",
    "        null_4.append(cl)\n",
    "# null_4 is the list of columns with 4% missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's see minutes of usage boxplots for total_ic_mou_6\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x='churn', y='total_ic_mou_6', data=telecom)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='churn', y='total_ic_mou_7', data=telecom)\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x='churn', y='total_ic_mou_8', data=telecom)\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's see minutes of usage boxplots for total_og_mou_6\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x='churn', y='total_og_mou_6', data=telecom)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='churn', y='total_og_mou_7', data=telecom)\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x='churn', y='total_og_mou_8', data=telecom)\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All the columns with 4 percent missing values are from 8th month(_8 at the end). \n",
    "- From the boxplot above those who are going to churn in 9th month, there is significant drop in total_ic_mou_8 and total_og_mou_8.Which implies customers have stopped getting any type of incoming or outgoing calls.\n",
    "- Therefore in the columns with _mou_8 at the end we can impute 0 for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nl in null_4:\n",
    "    telecom[nl].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(round(100*(telecom.isnull().sum()/len(telecom.index)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping rows with missing values\n",
    "telecom= telecom.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of the object datatype columns are of dates. We are dropping those here\n",
    "obj_col =telecom.select_dtypes(include=['object']).columns\n",
    "obj_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Formatting columns which have date in them\n",
    "for oc in obj_col:\n",
    "    telecom[oc]= pd.to_datetime(telecom[oc],format = \"%m/%d/%Y\")\n",
    "## Removing month and year and only keeping date(day of the month) as month is already captured in columns name\n",
    "telecom['last_day_of_month_6'] = telecom['last_date_of_month_6'].dt.day\n",
    "telecom['last_day_of_month_7'] = telecom['last_date_of_month_7'].dt.day\n",
    "telecom['last_day_of_month_8'] = telecom['last_date_of_month_8'].dt.day\n",
    "telecom['day_of_last_rech_6'] = telecom['date_of_last_rech_6'].dt.day\n",
    "telecom['day_of_last_rech_7'] = telecom['date_of_last_rech_7'].dt.day\n",
    "telecom['day_of_last_rech_8'] = telecom['date_of_last_rech_8'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom= telecom.drop(obj_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating separate dataframe for categorical variables\n",
    "cat_list= ['night_pck_user_6','night_pck_user_7','night_pck_user_8','fb_user_6','fb_user_7','fb_user_8']\n",
    "telecom_categorical= telecom[cat_list]\n",
    "telecom_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating another dataframe for numerical variables\n",
    "telecom_numerical = telecom.drop(cat_list, axis=1)\n",
    "telecom_numerical = telecom_numerical.drop('churn', axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_numerical.nunique().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To capture maximum variance let's drop the columns which have only one value in them\n",
    "telecom_numerical = telecom_numerical.loc[:,telecom.apply(pd.Series.nunique) >1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_numerical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_col= telecom_numerical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_categorical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame = pd.concat([telecom_numerical,telecom_categorical, telecom['churn']], axis=1)\n",
    "main_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "#### Here we're aiming to understand behaviour and recognize pattern of churners before they churned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets see the correlation matrix first\n",
    "\n",
    "# figure size\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "# heatmap\n",
    "sns.heatmap(main_frame.corr(), cmap=\"YlGnBu\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since the feature space is too large it is very difficult to analyse the correlation matrix above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of different recharge and data usage\n",
    "- Analysis of avg_rech_amt_6/7/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values = 'avg_rech_amt',\n",
    "                      index = 'churn', \n",
    "                      aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='churn', y='avg_rech_amt', data=main_frame)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's analyse last_day_rch_amt6/7/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values = ['last_day_rch_amt_6','last_day_rch_amt_7','last_day_rch_amt_8'],\n",
    "                      index = 'churn', \n",
    "                      aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is significant drop in mean last_day_rch_amt_8 for the churners who are going to churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x='churn', y='last_day_rch_amt_6', data=main_frame)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='churn', y='last_day_rch_amt_7', data=main_frame)\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x='churn', y='last_day_rch_amt_8', data=main_frame)\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's analyse __total_rch_data_6/7/8__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values = ['total_rech_data_6','total_rech_data_7','total_rech_data_8'],\n",
    "                      index = 'churn', \n",
    "                      aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x='churn', y='total_rech_data_6', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.barplot(x='churn', y='total_rech_data_7', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.barplot(x='churn', y='total_rech_data_8', data=main_frame)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame[['total_rech_data_6','total_rech_data_7','total_rech_data_8']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __av_rech_amt_data__ analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values = ['av_rech_amt_data_6','av_rech_amt_data_7','av_rech_amt_data_8'],\n",
    "                      index = 'churn', \n",
    "                      aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x='churn', y='av_rech_amt_data_6', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.barplot(x='churn', y='av_rech_amt_data_7', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.barplot(x='churn', y='av_rech_amt_data_8', data=main_frame)\n",
    "# plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- total rech_amt_data_6/7/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values = ['total_rech_amt_data_6','total_rech_amt_data_7','total_rech_amt_data_8'],\n",
    "                      index = 'churn', \n",
    "                      aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x='churn', y='total_rech_amt_data_6', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.barplot(x='churn', y='total_rech_amt_data_7', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.barplot(x='churn', y='total_rech_amt_data_8', data=main_frame)\n",
    "# plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __vol_3g_mb__ analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values = ['vol_3g_mb_6','vol_3g_mb_7','vol_3g_mb_8'],\n",
    "                      index = 'churn', \n",
    "                      aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x='churn', y='vol_3g_mb_6', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.barplot(x='churn', y='vol_3g_mb_7', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.barplot(x='churn', y='vol_3g_mb_8', data=main_frame)\n",
    "# plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __max_rech_data_6/7/8__ analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values = ['max_rech_data_6','max_rech_data_7','max_rech_data_8'],\n",
    "                      index = 'churn', \n",
    "                      aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x='churn', y='max_rech_data_6', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.barplot(x='churn', y='max_rech_data_7', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.barplot(x='churn', y='max_rech_data_8', data=main_frame)\n",
    "# plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __max_rech_data_6/7/8__ analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values = ['max_rech_amt_6','max_rech_amt_7','max_rech_amt_8'],\n",
    "                      index = 'churn', \n",
    "                      aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x='churn', y='max_rech_amt_6', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.barplot(x='churn', y='max_rech_amt_7', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.barplot(x='churn', y='max_rech_amt_8', data=main_frame)\n",
    "# plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of _Minutes of Usage_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's analyse __total_ic_mou_6/7/8__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values = ['total_ic_mou_6','total_ic_mou_7','total_ic_mou_8'],\n",
    "                      index = 'churn', \n",
    "                      aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is significant drop in mean __total_ic_mou_8__ for the churners who are going to churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x='churn', y='total_ic_mou_6', data=main_frame)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='churn', y='total_ic_mou_7', data=main_frame)\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x='churn', y='total_ic_mou_8', data=main_frame)\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's analyse __total_og_mou_6/7/8__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values = ['total_og_mou_6','total_og_mou_7','total_og_mou_8'],\n",
    "                      index = 'churn', \n",
    "                      aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is significant drop in mean __total_og_mou_8__ for the churners who are going to churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x='churn', y='total_og_mou_6', data=main_frame)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='churn', y='total_og_mou_7', data=main_frame)\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x='churn', y='total_og_mou_8', data=main_frame)\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above we saw significant drop in total minutes of usage variable in 8th month compare to what it wqas in 6th and 7th month. \n",
    "- Let's break it down further in roaming and local minutes of usage and see what we can find:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's analyse __roam_og_mou_6/7/8 and roam_ic_mou_6/7/8__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values = ['roam_og_mou_6','roam_og_mou_7','roam_og_mou_8'],\n",
    "                      index = 'churn', \n",
    "                      aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values = ['roam_ic_mou_6','roam_ic_mou_7','roam_ic_mou_8'],\n",
    "                      index = 'churn', \n",
    "                      aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x='churn', y='roam_og_mou_6', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='churn', y='roam_og_mou_7', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x='churn', y='roam_og_mou_8', data=main_frame)\n",
    "# plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x='churn', y='roam_ic_mou_6', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='churn', y='roam_ic_mou_7', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x='churn', y='roam_ic_mou_8', data=main_frame)\n",
    "# plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see of loc_og/ic_mou explains anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values= ['loc_og_mou_6','loc_og_mou_7','loc_og_mou_8'],\n",
    "                       index= 'churn',\n",
    "                      aggfunc= 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values= ['loc_ic_mou_6','loc_ic_mou_7','loc_ic_mou_8'],\n",
    "                       index= 'churn',\n",
    "                      aggfunc= 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x='churn', y='loc_og_mou_6', data=main_frame)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='churn', y='loc_og_mou_7', data=main_frame)\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x='churn', y='loc_og_mou_8', data=main_frame)\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x='churn', y='loc_ic_mou_6', data=main_frame)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='churn', y='loc_ic_mou_7', data=main_frame)\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x='churn', y='loc_ic_mou_8', data=main_frame)\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analysis of isd_og_mou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values= ['isd_og_mou_6','isd_og_mou_7','isd_og_mou_8'],\n",
    "                      index='churn',\n",
    "                      aggfunc= 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x='churn', y='isd_og_mou_6', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.barplot(x='churn', y='isd_og_mou_7', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.barplot(x='churn', y='isd_og_mou_8', data=main_frame)\n",
    "# plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analysis of isd_ic_mou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values= ['isd_ic_mou_6','isd_ic_mou_7','isd_ic_mou_8'],\n",
    "                     index= 'churn',\n",
    "                      aggfunc= 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x='churn', y='isd_ic_mou_6', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.barplot(x='churn', y='isd_ic_mou_7', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.barplot(x='churn', y='isd_ic_mou_8', data=main_frame)\n",
    "# plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame[['isd_ic_mou_6','isd_ic_mou_7','isd_ic_mou_8','isd_og_mou_6','isd_og_mou_7','isd_og_mou_8']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- std_og_mou_6/7/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values=['std_og_mou_6','std_og_mou_7','std_og_mou_8'],\n",
    "                      index= 'churn',\n",
    "                      aggfunc= 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x='churn', y='std_og_mou_6', data=main_frame)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='churn', y='std_og_mou_7', data=main_frame)\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x='churn', y='std_og_mou_8', data=main_frame)\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- std_ic_mou_6/7/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values=['std_ic_mou_6','std_ic_mou_7','std_ic_mou_8'],\n",
    "                      index= 'churn',\n",
    "                      aggfunc= 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x='churn', y='std_ic_mou_6', data=main_frame)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='churn', y='std_ic_mou_7', data=main_frame)\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x='churn', y='std_ic_mou_8', data=main_frame)\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of _Average revenue per user_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.pivot_table(values=['arpu_6','arpu_7','arpu_8'],\n",
    "                      index= 'churn',\n",
    "                      aggfunc= 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x='churn', y='arpu_6', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.barplot(x='churn', y='arpu_7', data=main_frame)\n",
    "# plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.barplot(x='churn', y='arpu_8', data=main_frame)\n",
    "# plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's also look at the distribution of day of last recharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.distplot(main_frame['day_of_last_rech_6'])\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.distplot(main_frame['day_of_last_rech_7'])\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.distplot(main_frame['day_of_last_rech_8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.groupby(['churn','day_of_last_rech_6'])['mobile_number'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.groupby(['churn','day_of_last_rech_7'])['mobile_number'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.groupby(['churn','day_of_last_rech_8'])['mobile_number'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model Building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seperating independent variables and target variables\n",
    "X = main_frame.drop(['mobile_number','churn'], axis=1)\n",
    "y = main_frame[['churn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating another copy for logistic regression as it needs scaled data and ree models don't\n",
    "Xl= copy.copy(X)\n",
    "yl= copy.copy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### standardising the data.\n",
    "### Since Xl is copy of X we can use it in the following way so that we don't end up losing name of the columns.\n",
    "Xl = (X-X.mean())/X.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each category (level) of a categorical variable, computing the churn rate (i.e. no. of churn/non-churn + churn), which will be a number (fraction) and replacing each categorical level with this number. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the churn rate\n",
    "npu_6 = main_frame.groupby('night_pck_user_6')['churn'].mean()\n",
    "npu_7 = main_frame.groupby('night_pck_user_7')['churn'].mean()\n",
    "npu_8 = main_frame.groupby('night_pck_user_8')['churn'].mean()\n",
    "\n",
    "fbu_6 = main_frame.groupby('fb_user_6')['churn'].mean()\n",
    "fbu_7 = main_frame.groupby('fb_user_7')['churn'].mean()\n",
    "fbu_8 = main_frame.groupby('fb_user_8')['churn'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npu_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionaries cosnsisting of churn rate for categories\n",
    "np6= npu_6.to_dict()\n",
    "np7= npu_7.to_dict()\n",
    "np8= npu_8.to_dict()\n",
    "\n",
    "fb6= fbu_6.to_dict()\n",
    "fb7= fbu_7.to_dict()\n",
    "fb8= fbu_8.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the categorical colummn values by the map created in the dictionaries above\n",
    "Xl= Xl.replace({\"night_pck_user_6\": np6})\n",
    "Xl= Xl.replace({\"night_pck_user_7\": np7})\n",
    "Xl= Xl.replace({\"night_pck_user_8\": np8})\n",
    "Xl= Xl.replace({\"fb_user_6\": fb6})\n",
    "Xl= Xl.replace({\"fb_user_7\": fb7})\n",
    "Xl= Xl.replace({\"fb_user_8\": fb8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training and tesing sets\n",
    "Xl_train, Xl_test, yl_train, yl_test= train_test_split(Xl, yl, train_size= 0.7, test_size= 0.3, random_state= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage churner in training data set\n",
    "yl_train[yl_train['churn']==1].count()/yl_train['churn'].count() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In training data set the churning rate is 6.77. This rate is very low and can lead to very high bias.\n",
    "- To counter this we are going to use oversampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving column names as after applying SMOTE() dataframe gets converted to numpy array.\n",
    "Xl_train_col = Xl_train.columns\n",
    "yl_train_col = yl_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are applying SMOTE and incresing the churn rate to 12.2\n",
    "Xl_train_res, yl_train_res = SMOTE(0.14).fit_sample(Xl_train, yl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Xl_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert this numpy array to pandas dataframe\n",
    "# Converting numpy arrays Xl_train_res, yl_train_res to pandas dataframe after SMOTE\n",
    "Xl_train_res = pd.DataFrame(Xl_train_res,columns= Xl_train_col)\n",
    "yl_train_res = pd.DataFrame(yl_train_res,columns= yl_train_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage churner in training data set\n",
    "yl_train_res[yl_train_res['churn']==1].count()/yl_train_res['churn'].count() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out exactly ho many components explain 85% of variance.\n",
    "pca = PCA(0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pca = pca.fit_transform(Xl_train_res)\n",
    "df_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pca = pca.transform(Xl_test)\n",
    "df_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg_pca = logreg.fit(df_train_pca,yl_train_res)\n",
    "#Making prediction on the test data\n",
    "y_pred_probs = logreg_pca.predict_proba(df_test_pca)[:,1]\n",
    "# AUC-ROC value\n",
    "\"{:2.2f}\".format(metrics.roc_auc_score(yl_test, y_pred_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pca = logreg_pca.predict(df_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(yl_test, y_pred_pca ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = pd.DataFrame(y_pred_probs,columns=['churn_probability'])\n",
    "\n",
    "y_pred_1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "y_test_df = pd.DataFrame(yl_test)\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Putting CustID to index\n",
    "y_test_df['ID'] = y_test_df.index\n",
    "# # Removing index for both dataframes to append them side by side \n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)\n",
    "# # Appending y_test_df and y_pred_1\n",
    "y_pred_final = pd.concat([y_test_df,y_pred_1],axis=1)\n",
    "# # Rearranging the columns\n",
    "y_pred_final = y_pred_final.reindex_axis(['ID','churn','churn_probability'], axis=1)\n",
    "# # Let's see the head of y_pred_final\n",
    "y_pred_final.head()\n",
    "# y_test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new column 'predicted' with 1 if Churn_Prob>0.5 else 0\n",
    "y_pred_final['predicted'] = y_pred_final.churn_probability.map( lambda x: 1 if x > 0.5 else 0)\n",
    "# Let's see the head\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create columns with different probability cutoffs \n",
    "numbers = [float(x)/100 for x in range(0,51)]\n",
    "for i in numbers:\n",
    "    y_pred_final[i]= y_pred_final.churn_probability.map( lambda x: 1 if x > i else 0)\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finding optimal cutoff point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "num = [float(x)/100 for x in range(0,51)]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix( y_pred_final.churn, y_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    sensi = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    speci = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From the plot above the optimal cut off probability is 0.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix( y_pred_final.churn, y_pred_final[0.12] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred_final.churn,y_pred_final[0.12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is going to be our final model with cut off probability of 0.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size= 0.7, test_size= 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on training data with default hyperparameters\n",
    "shallow_tree = DecisionTreeClassifier(max_depth=3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will predict the the label\n",
    "y_pred_dt1 = shallow_tree.predict(X_test)\n",
    "\n",
    "#This will calculate probabilities\n",
    "y_pred_dt2 = shallow_tree.predict_proba(X_test)\n",
    "\n",
    "dt_accuracy = metrics.accuracy_score(y_test, y_pred_dt1)\n",
    "dt_auc= metrics.roc_auc_score(y_test, y_pred_dt2[:,1])\n",
    "print('This decision tree has accuracy rate of',dt_accuracy,'and ROC-AUC',dt_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_dt = metrics.confusion_matrix( y_test, y_pred_dt1)\n",
    "confusion_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the report of our default model\n",
    "print(classification_report(y_test,y_pred_dt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image  \n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot, graphviz\n",
    "\n",
    "# Putting features\n",
    "features = list(X.columns)\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()  \n",
    "export_graphviz(shallow_tree, out_file=dot_data,\n",
    "                feature_names=features, filled=True,rounded=True)\n",
    "\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph[0].create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with default hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc1= RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "rfc1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will predict the the label\n",
    "y_pred_rf11 = rfc1.predict(X_test)\n",
    "\n",
    "#This will calculate probabilities\n",
    "y_pred_rf12 = rfc1.predict_proba(X_test)\n",
    "\n",
    "rf1_accuracy = metrics.accuracy_score(y_test, y_pred_rf11)\n",
    "rf1_auc= metrics.roc_auc_score(y_test, y_pred_rf12[:,1])\n",
    "print('This decision tree has accuracy rate of',rf1_accuracy,'and ROC-AUC',rf1_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_rf1 = metrics.confusion_matrix( y_test, y_pred_rf11)\n",
    "confusion_rf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the report of our default model\n",
    "print(classification_report(y_test,y_pred_rf11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc2 = RandomForestClassifier(bootstrap=True,\n",
    "                             max_depth=4,\n",
    "                             max_features=40,\n",
    "                             n_estimators=400)\n",
    "#                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "rfc2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will predict the the label\n",
    "y_pred_rf21 = rfc2.predict(X_test)\n",
    "\n",
    "#This will calculate probabilities\n",
    "y_pred_rf22 = rfc2.predict_proba(X_test)\n",
    "\n",
    "\n",
    "rf2_accuracy = metrics.accuracy_score(y_test, y_pred_rf21)\n",
    "rf2_auc= metrics.roc_auc_score(y_test, y_pred_rf22[:,1])\n",
    "print('This random forest has accuracy rate of',rf2_accuracy,'and ROC-AUC',rf2_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see th confusion matrix for this random forest\n",
    "print(metrics.confusion_matrix( y_test, y_pred_rf21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the report of our default model\n",
    "print(classification_report(y_test,y_pred_rf21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaboost with the shallow_tree as base estimator.\n",
    "# we're using the same shallow_tree in the very beginning of decision tree model.\n",
    "\n",
    "estimators = list(range(1, 70, 5))\n",
    "\n",
    "abc_scores = []\n",
    "for n_est in estimators:\n",
    "    ABC = AdaBoostClassifier(\n",
    "    base_estimator=shallow_tree, \n",
    "    n_estimators = n_est)\n",
    "    \n",
    "    ABC.fit(X_train, y_train)\n",
    "    y_pred_ab = ABC.predict_proba(X_test)\n",
    "    score = metrics.roc_auc_score(y_test, y_pred_ab[:,1])\n",
    "    abc_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(abc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in range (1,70,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot test scores and n_estimators\n",
    "# plot\n",
    "plt.plot(estimators, abc_scores)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('ROC-AUC')\n",
    "plt.ylim([0.7, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For 11 estimators we are getting maximum ROC-AUC.\n",
    "- Let's evaluate it further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_final= AdaBoostClassifier(\n",
    "    base_estimator=shallow_tree, \n",
    "    n_estimators = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will predict the the label\n",
    "y_pred_ab1 = abc_final.predict(X_test)\n",
    "\n",
    "#This will calculate probabilities\n",
    "y_pred_ab2 = abc_final.predict_proba(X_test)\n",
    "\n",
    "\n",
    "abc_accuracy = metrics.accuracy_score(y_test, y_pred_ab1)\n",
    "abc_auc= metrics.roc_auc_score(y_test, y_pred_ab2[:,1])\n",
    "print('This AdaBoost model gives has accuracy rate of',abc_accuracy,'and ROC-AUC',abc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix( y_test, y_pred_ab1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the report of our default model\n",
    "print(classification_report(y_test,y_pred_ab1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,30))\n",
    "sns.barplot(x=abc_final.feature_importances_ ,y= X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XgBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running first model(Default hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on training data with default hyperparameters\n",
    "model_xg = XGBClassifier()\n",
    "model_xg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "# use predict_proba since we need probabilities to compute auc\n",
    "y_pred_xg1 = model_xg.predict(X_test)\n",
    "y_pred_xg2 = model_xg.predict_proba(X_test)\n",
    "\n",
    "xg_accuracy = metrics.accuracy_score(y_test, y_pred_xg1)\n",
    "xg_auc= metrics.roc_auc_score(y_test, y_pred_xg2[:,1])\n",
    "print('This XGBoost model gives has accuracy rate of',xg_accuracy,'and ROC-AUC',xg_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred_xg1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Grid Search to Find Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning with XGBoost\n",
    "\n",
    "# creating a KFold object \n",
    "folds = 3\n",
    "\n",
    "# specify range of hyperparameters\n",
    "param_grid = {'learning_rate': [0.2, 0.4, 0.6], \n",
    "             'subsample': [0.3, 0.6, 0.9]}          \n",
    "\n",
    "\n",
    "# specify model\n",
    "xgb_model = XGBClassifier(max_depth=3)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "xgb_cv = GridSearchCV(estimator = xgb_model, \n",
    "                        param_grid = param_grid, \n",
    "                        scoring= 'roc_auc', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "xgb_cv.fit(X_train, y_train)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv results\n",
    "xg_cv_results = pd.DataFrame(xgb_cv.cv_results_)\n",
    "xg_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We can get ROC_AUC of',xgb_cv.best_score_,'using',xgb_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_cv_results['param_learning_rate'] = xg_cv_results['param_learning_rate'].astype('float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "param_grid = {'learning_rate': [0.2, 0.4, 0.6], \n",
    "             'subsample': [0.3, 0.6, 0.9]} \n",
    "\n",
    "\n",
    "for n, subsample in enumerate(param_grid['subsample']):\n",
    "    \n",
    "\n",
    "    # subplot 1/n\n",
    "    plt.subplot(1,len(param_grid['subsample']), n+1)\n",
    "    df = xg_cv_results[xg_cv_results['param_subsample']==subsample]\n",
    "\n",
    "    plt.plot(df[\"param_learning_rate\"], df[\"mean_test_score\"])\n",
    "    plt.plot(df[\"param_learning_rate\"], df[\"mean_train_score\"])\n",
    "    plt.xlabel('learning_rate')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.title(\"subsample={0}\".format(subsample))\n",
    "    plt.ylim([0.8, 1])\n",
    "    plt.legend(['test score', 'train score'], loc='upper left')\n",
    "    plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting hyperparameters from above plots as: learning_rate=0.2, subsample=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'learning_rate': 0.2,\n",
    "          'max_depth': 3, \n",
    "          'subsample':0.6,\n",
    "         'objective':'binary:logistic'}\n",
    "\n",
    "# fit model on training data\n",
    "xg_final = XGBClassifier(params = params)\n",
    "xg_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC score\n",
    "# predict\n",
    "y_pred_xgb1 = xg_final.predict(X_test)\n",
    "y_pred_xgb2 = xg_final.predict_proba(X_test)\n",
    "\n",
    "xg_final_accuracy = metrics.accuracy_score(y_test, y_pred_xgb1)\n",
    "xg_final_auc = metrics.roc_auc_score(y_test, y_pred_xgb2[:,1])\n",
    "\n",
    "print('This XGBoost model gives has accuracy rate of',xg_final_accuracy,'and ROC-AUC',xg_final_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "print(metrics.confusion_matrix( y_test, y_pred_xgb1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_xgb1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = dict(zip(X_train.columns, xg_final.feature_importances_))\n",
    "\n",
    "imp_gain= xg_final.get_booster().get_score(importance_type='gain')\n",
    "# gain_val = list(imp_gain.values())\n",
    "\n",
    "imp_weight= xg_final.get_booster().get_score(importance_type='weight')\n",
    "# weight_val = list(imp_weight.values())\n",
    "\n",
    "imp_cover= xg_final.get_booster().get_score(importance_type='cover')\n",
    "# cover_val = list(imp_cover.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_data= sorted(importance.items(), key=lambda x:x[1], reverse=True)\n",
    "xi_val = [xi[0] for xi in impt_data]\n",
    "yi_val = [xi[1] for xi in impt_data]\n",
    "plt.figure(figsize=(10,30))\n",
    "plt.title('Feature_Importance')\n",
    "sns.barplot(y= xi_val, x=yi_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_data= sorted(imp_gain.items(), key=lambda x:x[1], reverse=True)\n",
    "xg_val = [xg[0] for xg in gain_data]\n",
    "yg_val = [xg[1] for xg in gain_data]\n",
    "plt.figure(figsize=(10,30))\n",
    "plt.title('Gain')\n",
    "# sns.barplot(y= list(imp_gain.keys()),x= gain_val)\n",
    "sns.barplot(y= xg_val, x=yg_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_data= sorted(imp_cover.items(), key=lambda x:x[1], reverse=True)\n",
    "xc_val = [xc[0] for xc in cover_data]\n",
    "yc_val = [xc[1] for xc in cover_data]\n",
    "plt.figure(figsize=(10,30))\n",
    "plt.title('Cover')\n",
    "# sns.barplot(y= list(imp_cover.keys()),x= weight_val)\n",
    "sns.barplot(y= xc_val, x=yc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "\n",
    "- __Our predictive model with PCA and logistic regression managed to find churners correctly 82 percent of the time while maintaining overall model accuracy at 81.61 percent at cut-off probability of 0.12.__\n",
    "\n",
    "- To identify important driving factors, we trained various tree models and among those we are choosing XgBoost and it has necessary metrics associated with it to give clear insight.\n",
    "\n",
    "#### Feature Importance:\n",
    "__model.feature_importances__ tells us importance of a feature in generating the prediction. Higher the value more important is the feature in determining the prediction.(in our case which customer is going to churn). When we implemented this on our xg_final model we got following top 10 important features:\n",
    "- 'day_of_last_rech_8', 'roam_og_mou_8', 'last_day_rch_amt_8', 'total_ic_mou_8', 'sep_vbc_3g', 'av_rech_amt_data_8', 'loc_ic_mou_8', 'aon', 'avg_rech', 'roam_og_mou_7'.\n",
    "\n",
    "__model gain__ The Gain implies the relative contribution of the corresponding feature to the model calculated by taking each feature's contribution for each tree in the model. A higher value of this metric when compared to another feature implies it is more important for generating a prediction.\n",
    "- 'total_ic_mou_8', 'loc_ic_mou_8', 'fb_user_8', 'av_rech_amt_data_8', 'total_rech_amt_data_8', 'last_day_rch_amt_8', 'std_og_mou_7', 'roam_og_mou_8', 'loc_og_t2f_mou_8', 'total_rech_num_7'.\n",
    "\n",
    "\n",
    "## Observations and inferences:\n",
    "- 6th and 7th month are good phase and 8th month is action phase\n",
    "\n",
    "- If a customer shows reduction in total incoming calls minutes of usage(total_ic_mou_8) and local incoming calls minutes of usage(loc_ic_mou_8) in action phase to 0 or less than average value of good months, then he/she is most likely to churn in churn phase.\n",
    "##### Therefore if we want to reduce the churn rate then it's very important to target customers for whome total incoming minutes of usge and local incoming minutes of usage is 0 or less than average of good phase(average: (total_ic_mou_6+total_ic_mou_7)/2 ) in action phase that is 8th  month.\n",
    "\n",
    "- Also the customers who are going to churn show significant reduction in _average recharge amount data_ in action phase compare to customers who have not churned in action phase. \n",
    "##### Therefore from EDA section, customers who show less  average  recharge amount data in action phase(av_rech_amt_data_8) compare to 6th and 7th month should be targeted for less churning rate.\n",
    "\n",
    "- Last day recharge amount of action phase (last_day_rch_amt_8) is also a important indicator. Interestingly customers who are going to churn show 0 or less than average last day recharge amount not only for 8th month but also for 7th month.(plot from EDA section).\n",
    "##### Therefore to target customers based on last_day_rch_amt_, we can  look at both last_day_rch_amt_7 and last_day_rch_amt_8 as most of those who are going to churn later show similar behaviour  on the last day recharge amount of 7th and 8th month.\n",
    "\n",
    "- From the barplot in EDA, customers who are going to churn show small reduction in total recharge amount data 7 compare total recharge amount data 7 but huge fall from total recharge amount data 7 to total recharge amount data 8.\n",
    "\n",
    "###### From the groupby tables in EDA section, customers for whome last day of recharge has shifted to the first week are very likely to churn. As we can see in the customers with label 1 are less in the the first week of 6th and 7th month but are relatively large in 8th month.\n",
    "\n",
    "\n",
    "###### Customers who are going to churn also show significant drop in std outgoing minutes of usage in 8th month compare to 6th and 7th month "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
